{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "# ## Plotly\n",
    "# import plotly.offline as py\n",
    "# import plotly.graph_objs as go\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.3class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.4class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/rating.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>3class_label</th>\n",
       "      <th>4class_label</th>\n",
       "      <th>rating</th>\n",
       "      <th>subj_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>in my opinion , a movie reviewer's most import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>you can watch this movie , that is based on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is asking a lot to believe , and though i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>no heroes and no story are the main attributes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is not an art movie , yet i saw it an art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  3class_label  4class_label  rating  \\\n",
       "0  29420             0             0     0.1   \n",
       "1  17219             0             0     0.2   \n",
       "2  18406             0             0     0.2   \n",
       "3  18648             0             0     0.2   \n",
       "4  20021             0             0     0.2   \n",
       "\n",
       "                                     subj_extraction  \n",
       "0  in my opinion , a movie reviewer's most import...  \n",
       "1  you can watch this movie , that is based on a ...  \n",
       "2  this is asking a lot to believe , and though i...  \n",
       "3  no heroes and no story are the main attributes...  \n",
       "4  this is not an art movie , yet i saw it an art...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dennis = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "dennis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dennis[\"strongly neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "dennis[\"strongly pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "dennis['n']=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "y_d_encode = dennis[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_d, xvalid_d, ytrain_d, yvalid_d = train_test_split(list(dennis['subj_extraction']), y_d, \n",
    "                                                  stratify=y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_d, xvalid_d, ytrain_d_encode, yvalid_d_encode = train_test_split(dennis['subj_extraction'], y_d_encode, \n",
    "                                                  stratify=y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924,)\n",
      "(924, 3)\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "# we use x_train as docs, y_d as labels\n",
    "print (ytrain_d.shape)\n",
    "print (ytrain_d_encode.shape)\n",
    "print(len(xtrain_d[1].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(c,f):\n",
    "    return c,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 3, 9, 10, 11, 5, 12, 1, 13, 14, 15], [2, 16, 6, 4, 2, 17, 18, 19, 1, 20, 7, 21, 2, 6, 22, 7, 23, 4, 3, 24, 25], [26, 1, 27, 4, 2, 28], [5, 1, 3, 29, 30, 31, 32]]\n",
      "33\n",
      "{'is': 1, 'the': 2, 'a': 3, 'to': 4, 'it': 5, 'title': 6, 'in': 7, 'having': 8, 'dark': 9, 'humor': 10, 'about': 11, 'that': 12, 'funnier': 13, 'than': 14, 'hell': 15, 'american': 16, 'film': 17, 'boiling': 18, 'point': 19, 'misleading': 20, 'japanese': 21, 'refers': 22, 'slang': 23, 'baseball': 24, 'score': 25, 'she': 26, 'going': 27, 'library': 28, 'call': 29, 'for': 30, 'artistic': 31, 'freedom': 32}\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "docs = ['having a dark humor about it that is funnier than hell', 'the american title to the film , boiling point , is misleading : in japanese the title refers in slang to a baseball score', 'she is going to the library', \n",
    "      'it is a call for artistic freedom']\n",
    "def padded_doc(docs):\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(docs)\n",
    "    # integer encode the documents\n",
    "    encoded_docs = t.texts_to_sequences(docs)\n",
    "    # pad documents to a max length of 4 words\n",
    "    max_length = 10\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    # print(padded_docs)\n",
    "    return padded_docs\n",
    "padded_doc(docs)\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "print (t.texts_to_sequences(docs))\n",
    "# p_d = padded_doc(docs)\n",
    "# gd.get_glove_m(p_d, )\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)\n",
    "print (t.word_index)\n",
    "print (padded_doc(docs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,f = x(7,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glove_dl21 as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, embedding_matrix, padded_docs = gd.get_glove_m(xtrain_d, ytrain_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.27085999,  0.044006  , -0.02026   , ..., -0.4923    ,\n",
       "         0.63687003,  0.23642001],\n",
       "       ..., \n",
       "       [ 0.49579999, -0.41578001,  0.19389001, ..., -0.30579001,\n",
       "         0.45275   ,  0.76160002],\n",
       "       [-0.46489999, -1.06060004, -0.10805   , ...,  0.036301  ,\n",
       "        -0.85459   ,  0.29347   ],\n",
       "       [-0.032544  ,  0.093303  ,  0.0076568 , ...,  0.63237   ,\n",
       "         0.43331   ,  0.84724998]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_padded_docs = gd.padded_doc(xvalid_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17911, 100)\n",
      "17911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, 400)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (embedding_matrix.shape)\n",
    "print (vocab_size)\n",
    "padded_docs.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.2802 - acc: 0.7868\n",
      "Epoch 2/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.2553 - acc: 0.8074\n",
      "Epoch 3/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.2705 - acc: 0.8128\n",
      "Epoch 4/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.2530 - acc: 0.8052\n",
      "Epoch 5/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.2502 - acc: 0.8225\n",
      "Epoch 6/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.2546 - acc: 0.8193\n",
      "Epoch 7/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.2211 - acc: 0.8214\n",
      "Epoch 8/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.2184 - acc: 0.8225\n",
      "Epoch 9/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.2363 - acc: 0.8160\n",
      "Epoch 10/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.2018 - acc: 0.8398\n",
      "Epoch 11/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.2132 - acc: 0.8355\n",
      "Epoch 12/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1758 - acc: 0.8474\n",
      "Epoch 13/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.2166 - acc: 0.8236\n",
      "Epoch 14/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.2113 - acc: 0.8268\n",
      "Epoch 15/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.2103 - acc: 0.8236\n",
      "Epoch 16/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1942 - acc: 0.8279\n",
      "Epoch 17/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1764 - acc: 0.8442\n",
      "Epoch 18/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.2006 - acc: 0.8377\n",
      "Epoch 19/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1903 - acc: 0.8279\n",
      "Epoch 20/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1402 - acc: 0.8485\n",
      "Epoch 21/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1426 - acc: 0.8517\n",
      "Epoch 22/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1794 - acc: 0.8377\n",
      "Epoch 23/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1787 - acc: 0.8420\n",
      "Epoch 24/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1775 - acc: 0.8398\n",
      "Epoch 25/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1420 - acc: 0.8561\n",
      "Epoch 26/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.1640 - acc: 0.8387\n",
      "Epoch 27/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.1350 - acc: 0.8463\n",
      "Epoch 28/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1689 - acc: 0.8463\n",
      "Epoch 29/50\n",
      "924/924 [==============================] - 5s 6ms/step - loss: 0.1802 - acc: 0.8431\n",
      "Epoch 30/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1628 - acc: 0.8398A: 2s - loss: 0.13\n",
      "Epoch 31/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1355 - acc: 0.8463\n",
      "Epoch 32/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1489 - acc: 0.8506\n",
      "Epoch 33/50\n",
      "924/924 [==============================] - 5s 6ms/step - loss: 0.1365 - acc: 0.8561\n",
      "Epoch 34/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1237 - acc: 0.8582A: 0s - loss: 0.1317 - acc: \n",
      "Epoch 35/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1371 - acc: 0.8539\n",
      "Epoch 36/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1337 - acc: 0.8474\n",
      "Epoch 37/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.0893 - acc: 0.8647\n",
      "Epoch 38/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1163 - acc: 0.8561\n",
      "Epoch 39/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1238 - acc: 0.8485\n",
      "Epoch 40/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1096 - acc: 0.8712\n",
      "Epoch 41/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1289 - acc: 0.8636\n",
      "Epoch 42/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.0905 - acc: 0.8723\n",
      "Epoch 43/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1302 - acc: 0.8517\n",
      "Epoch 44/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1164 - acc: 0.8647\n",
      "Epoch 45/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1087 - acc: 0.8626\n",
      "Epoch 46/50\n",
      "924/924 [==============================] - 5s 6ms/step - loss: 0.1148 - acc: 0.8582\n",
      "Epoch 47/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1023 - acc: 0.8680\n",
      "Epoch 48/50\n",
      "924/924 [==============================] - 6s 6ms/step - loss: 0.0871 - acc: 0.8701\n",
      "Epoch 49/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.1082 - acc: 0.8615\n",
      "Epoch 50/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.0928 - acc: 0.8626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126c0b320>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "def build_model(embedding_matrix, vocab_size):\n",
    "    # define model\n",
    "    embedding_dim = 50\n",
    "    filter_sizes = (2, 4)\n",
    "    num_filters = 10\n",
    "    dropout_prob = (0.5, 0.8)\n",
    "    hidden_dims = 50\n",
    "\n",
    "    # Build model\n",
    "    sequence_length = 400\n",
    "    input_shape = (sequence_length,)\n",
    "\n",
    "    model_input = Input(shape=input_shape)\n",
    "\n",
    "    # Static model does not have embedding layer\n",
    "\n",
    "    z = Embedding(vocab_size, 100, input_length=sequence_length,weights=[embedding_matrix], name=\"embedding\")(model_input)\n",
    "\n",
    "    z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "    # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = Convolution1D(filters=num_filters,\n",
    "                             kernel_size=sz,\n",
    "                             padding=\"valid\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1)(z)\n",
    "        conv = MaxPooling1D(pool_size=1)(conv)\n",
    "        conv = Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "    z = Dropout(dropout_prob[1])(z)\n",
    "    z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "    model_output = Dense(3, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    weights = np.array([v for v in embedding_matrix])\n",
    "    print(\"Initializing embedding layer with glove weights, shape\", weights.shape)\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights([weights])\n",
    "    return model\n",
    "\n",
    "# # Initialize weights with word2vec\n",
    "# if model_type == \"CNN-non-static\":\n",
    "#     weights = np.array([v for v in embedding_weights.values()])\n",
    "#     print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "#     embedding_layer = model.get_layer(\"embedding\")\n",
    "#     embedding_layer.set_weights([weights])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_docs, ytrain_d_encode, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with glove weights, shape (17911, 100)\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 1.2077 - acc: 0.4400\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.9949 - acc: 0.4700\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.9172 - acc: 0.4900\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8941 - acc: 0.4900\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8334 - acc: 0.4900\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.8868 - acc: 0.4800\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7795 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6845 - acc: 0.4900\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.7949 - acc: 0.4900\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.7154 - acc: 0.4900\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6828 - acc: 0.5100\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6955 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5908 - acc: 0.5100\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.6264 - acc: 0.5100\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.5703 - acc: 0.4900\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.6261 - acc: 0.5100\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.7427 - acc: 0.5100\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.5200\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.6106 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5297 - acc: 0.5600\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5693 - acc: 0.5200\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5156 - acc: 0.5400\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4946 - acc: 0.5400\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5182 - acc: 0.5300\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5962 - acc: 0.5400\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.6131 - acc: 0.5800\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5148 - acc: 0.6000\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5980 - acc: 0.6000\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5556 - acc: 0.5600\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4433 - acc: 0.5500\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5181 - acc: 0.5500\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5016 - acc: 0.5400\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.4613 - acc: 0.5600\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4663 - acc: 0.5600\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4440 - acc: 0.5900\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4704 - acc: 0.6200\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4166 - acc: 0.6200\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4308 - acc: 0.7100\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.4486 - acc: 0.7800\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3969 - acc: 0.7800\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3196 - acc: 0.8400\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3937 - acc: 0.8200\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3904 - acc: 0.8200\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3498 - acc: 0.8600\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2641 - acc: 0.8300\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.4065 - acc: 0.8200\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3272 - acc: 0.8200\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2044 - acc: 0.8900\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2632 - acc: 0.8600\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3338 - acc: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1063e0898>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(embedding_matrix, vocab_size)\n",
    "model.fit(padded_docs[:100], ytrain_d_encode[:100], epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 400, 100)     1791100     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 100)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 399, 10)      2010        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 397, 10)      4010        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 399, 10)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 397, 10)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3990)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3970)         0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7960)         0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7960)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           398050      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            153         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,195,323\n",
      "Trainable params: 2,195,323\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visuliaze the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.660194\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test_padded_docs, yvalid_d, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d_glv = np.array(xtrain_d_glv)\n",
    "xvalid_d_glv = np.array(xvalid_d_glv)\n",
    "xtrain_d_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 300\n",
    "def model_3_layer():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation = 'relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "#     model.compile(optimizer='rmsprop', \n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "    model.compile(optimizer='rmsprop', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    print ('compile done')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_gl.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_cnn_json = model.to_json()\n",
    "with open(\"model_gl_cnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_cnn_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove_nn on the other writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/id.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "# label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"3class_label\"])\n",
    "\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.4class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/rating.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "james = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "james[\"strongly neg\"]=james.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "james[\"strongly pos\"]=james.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "james['n']=james.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "y_j_encode = james[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = james.subj_extraction.values\n",
    "y_j = james['3class_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_j, xvalid_j, ytrain_j, yvalid_j = train_test_split(x_j, y_j, \n",
    "                                                  stratify=y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_j, xvalid_j, ytrain_j_encode, yvalid_j_encode = train_test_split(x_j, y_j_encode, \n",
    "                                                  stratify=y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 300)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_j_glv = [g.sentence_vectorize(sent) for sent in xtrain_j]\n",
    "xvalid_j_glv = [g.sentence_vectorize(sent) for sent in xvalid_j]\n",
    "xtrain_j_glv = np.array(xtrain_j_glv)\n",
    "xvalid_j_glv = np.array(xvalid_j_glv)\n",
    "\n",
    "xtrain_j_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 400)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvalid_j_padded = gd.padded_doc(xvalid_j)\n",
    "xvalid_j_padded.shape\n",
    "xtrain_j_padded = gd.padded_doc(xtrain_j)\n",
    "xtrain_j_padded.shape\n",
    "# xtrain_j_padded = xtrain_j_padded[:924,:]\n",
    "# yvalid_j_encode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the pre_trained model and evaluate on james directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "acc: 69.72%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model_gl_cnn.json', 'r')\n",
    "loaded_model_cnn_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_cnn = model_from_json(loaded_model_cnn_json)\n",
    "# load weights into new model\n",
    "loaded_model_cnn.load_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model_cnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model_cnn.evaluate(xvalid_j_padded, yvalid_j_encode, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model_cnn.metrics_names[1], score[1]*100))\n",
    "# loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 400)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvalid_j_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_j, embedding_matrix_j, padded_docs_j = gd.get_glove_m(xtrain_j, ytrain_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(embedding_matrix_j, vocab_size_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x121ec3828>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "loaded_model_cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[7,188] = 18469 is not in [0, 17911)\n\t [[Node: embedding_9/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_9/embeddings/read, embedding_9/Cast)]]\n\nCaused by op 'embedding_9/Gather', defined at:\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-8542ee6fc8c1>\", line 6, in <module>\n    loaded_model_cnn = model_from_json(loaded_model_cnn_json)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\", line 349, in model_from_json\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 143, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 2517, in from_config\n    process_node(layer, node_data)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 2474, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1864, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[7,188] = 18469 is not in [0, 17911)\n\t [[Node: embedding_9/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_9/embeddings/read, embedding_9/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[7,188] = 18469 is not in [0, 17911)\n\t [[Node: embedding_9/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_9/embeddings/read, embedding_9/Cast)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-d1aa26207d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_j_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m924\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_j_encode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m924\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[7,188] = 18469 is not in [0, 17911)\n\t [[Node: embedding_9/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_9/embeddings/read, embedding_9/Cast)]]\n\nCaused by op 'embedding_9/Gather', defined at:\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-8542ee6fc8c1>\", line 6, in <module>\n    loaded_model_cnn = model_from_json(loaded_model_cnn_json)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\", line 349, in model_from_json\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 143, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 2517, in from_config\n    process_node(layer, node_data)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 2474, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1864, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[7,188] = 18469 is not in [0, 17911)\n\t [[Node: embedding_9/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_9/embeddings/read, embedding_9/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model_cnn.fit(xtrain_j_padded[:924,:], ytrain_j_encode[:924], epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn on glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128,5,\n",
    "                 activation='relu'))\n",
    "    model.add(MaxPooling1D(5))\n",
    "    model.add(Conv2D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 300\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 100\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000,\n",
    "                    400,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(xtrain_j_glv, ytrain_j_encode,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(xvalid_j_glv, yvalid_j_encode))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
