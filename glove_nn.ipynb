{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "# ## Plotly\n",
    "# import plotly.offline as py\n",
    "# import plotly.graph_objs as go\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.3class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.4class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/rating.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>3class_label</th>\n",
       "      <th>4class_label</th>\n",
       "      <th>rating</th>\n",
       "      <th>subj_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>in my opinion , a movie reviewer's most import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>you can watch this movie , that is based on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is asking a lot to believe , and though i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>no heroes and no story are the main attributes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is not an art movie , yet i saw it an art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  3class_label  4class_label  rating  \\\n",
       "0  29420             0             0     0.1   \n",
       "1  17219             0             0     0.2   \n",
       "2  18406             0             0     0.2   \n",
       "3  18648             0             0     0.2   \n",
       "4  20021             0             0     0.2   \n",
       "\n",
       "                                     subj_extraction  \n",
       "0  in my opinion , a movie reviewer's most import...  \n",
       "1  you can watch this movie , that is based on a ...  \n",
       "2  this is asking a lot to believe , and though i...  \n",
       "3  no heroes and no story are the main attributes...  \n",
       "4  this is not an art movie , yet i saw it an art...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dennis = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "dennis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dennis[\"strongly neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "dennis[\"strongly pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "dennis['n']=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "y_d_encode = dennis[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_d, xvalid_d, ytrain_d, yvalid_d = train_test_split(list(dennis['subj_extraction']), y_d, \n",
    "                                                  stratify=y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_d, xvalid_d, ytrain_d_encode, yvalid_d_encode = train_test_split(dennis['subj_extraction'], y_d_encode, \n",
    "                                                  stratify=y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use x_train as docs, y_d as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(c,f):\n",
    "    return c,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52343\n",
      ". . . -0.1573 -0.29517 0.30453 -0.54773 0.098293 -0.1776 0.21662 0.19261 -0.21101 0.53788 -0.047755 0.40675 0.023592 -0.32814 0.046858 0.19367 0.25565 -0.021019 -0.15957 -0.1023 0.20303 -0.043333 0.11618 -0.18486 0.0011948 -0.052301 0.34587 0.052335 0.16774 -0.21384 0.055947 0.24934 -0.12179 0.16749 0.28922 -0.033739 0.3015 -0.13241 0.092635 0.37155 -0.2884 -0.0052731 -0.001005 -0.51153 -0.28476 -0.20139 0.11837 -0.0055891 0.43604 0.16796 -0.2701 0.063957 -0.093253 -0.22079 0.36501 0.06545 0.23941 -0.19292 0.098293 0.12172 -0.1168 -0.027436 0.20507 -0.39139 -0.23111 0.46239 0.22888 -0.028415 -0.1798 0.23817 0.28093 -0.47935 0.23177 -0.35587 0.14246 0.11861 0.011018 0.091986 0.0054809 -0.39955 -0.40183 -0.10629 -0.30851 0.12383 -0.16737 -0.43569 0.4211 -0.57416 -0.19964 0.51312 0.090747 -0.21657 0.043519 0.24288 0.081134 0.49104 -0.33342 -0.31056 -0.3136 0.26931 -0.14402 0.33185 -0.21662 -0.072985 0.080603 -0.7266 -0.098385 -0.36233 -0.25346 0.1154 0.25738 0.15802 -0.15633 -0.024581 0.35673 0.31153 0.33475 -0.081155 -0.3061 0.019077 -0.049047 -0.11232 -0.07417 0.35596 -0.2642 0.012781 -0.20715 0.020223 0.054534 -0.28803 0.42863 -0.10312 0.24771 0.013196 0.19768 -0.013528 -0.15134 0.20307 -0.028973 -0.022706 -0.29199 -0.082062 0.19048 0.0053574 0.14067 -0.28675 0.21343 0.42428 -0.28186 -0.11801 -0.45227 -0.0067998 0.044784 -0.0062886 0.25087 0.34481 -0.64459 -0.20467 0.35007 0.1468 -0.14007 -0.0050219 -0.24053 0.41426 -0.40902 0.21141 0.25726 -0.4883 0.027066 0.56367 -0.39594 -0.035206 0.63079 0.14343 0.038315 0.32527 -0.080335 -0.20065 -0.30848 -0.0031591 0.15296 -0.21014 0.42143 -0.20944 -0.069285 0.13555 -0.020401 -0.22555 0.33491 0.16035 0.17739 -0.023627 0.097575 -0.19395 -0.018754 -0.119 -0.0067027 -0.4178 0.29027 0.13034 -0.30212 0.61173 -0.39918 -0.020191 -0.34531 -0.092082 0.46818 0.36671 0.21021 -0.053162 -0.37872 -0.14271 -0.13604 0.31715 -0.17227 -0.091266 0.16417 0.15069 0.53556 -0.29678 0.13965 -0.29788 0.1282 0.1971 -0.045515 -0.41355 -0.050333 -0.39015 -0.29579 -0.096145 -0.03151 0.053714 -0.37309 -0.36523 -0.17235 0.39251 -0.065909 -0.25267 -0.34448 -0.11503 0.43665 0.18832 0.20631 0.27801 -0.046077 0.13397 -0.091953 -0.098542 0.15811 0.2752 0.081383 0.32077 -0.10028 0.1088 -0.24836 0.10477 0.15243 -0.071302 0.12861 0.23061 0.0074864 0.090918 -0.12269 -0.14831 0.010586 0.35745 -0.23412 -0.23746 -0.22646 -0.27641 -0.1634 0.071909 -0.093884 0.21331 -0.20627 0.44406 0.34691 0.019064 0.034657 0.36789 0.32276 -0.31099 -0.023443 -0.77048 -0.26001 0.033961 -0.13874 0.051973 -0.0090509 0.27427 0.046548 -0.48214 -0.1437 -0.1975 -0.038126 -0.16555 0.071697 0.049449 0.15386 -0.81663\n",
      "\n",
      "303\n",
      "151102\n",
      ". . . . . -0.23773 -0.82788 0.82326 -0.91878 0.35868 0.1309 0.26195 -0.30068 0.42963 -1.5335 0.50492 0.59069 0.17763 -0.010302 -0.63371 -0.040832 0.69336 -0.85472 0.693 -0.44824 0.25476 0.17091 0.96056 -0.26516 0.17454 -0.27371 0.20591 -0.60435 -0.50923 0.36049 0.75756 -0.79493 0.12379 0.40019 0.56716 0.19451 0.15996 -0.07882 0.9756 0.54761 -0.25123 -0.70006 -0.78286 -0.95702 0.23045 -0.3643 0.80267 -0.30315 0.35283 -0.19961 0.71134 -0.94116 -0.086543 0.17827 0.40124 -0.071006 0.82202 -0.51055 0.47492 -0.0582 -0.2687 0.94119 0.0066621 -0.53636 -0.68859 0.27149 0.33482 0.53987 -0.72912 -0.53719 0.17591 -0.52643 0.42509 0.12433 -0.17178 0.53168 0.69058 0.703 0.17845 -0.39243 -0.50617 0.39575 0.18461 -0.26065 -0.61119 0.013174 0.32934 -0.4861 -0.46474 0.69677 0.47846 -0.43841 0.051551 0.4195 -0.36847 0.57844 0.053724 -0.026579 -0.5901 0.73221 -0.53987 -0.3428 -0.12343 -0.51213 -0.59237 -0.14589 0.094055 -0.48848 -0.09944 0.092527 0.76764 -0.21207 -0.2395 0.27517 0.27508 0.29604 0.01908 -0.64152 0.51208 0.30948 -0.47126 0.86562 -0.68993 0.19003 -0.78941 -0.10668 -0.64497 0.078153 -0.29598 -0.2383 0.40626 0.066945 0.021937 -0.28291 -0.34962 0.098551 -0.068353 0.06824 -0.17466 -0.21469 1.4612 0.30606 -0.28516 0.078682 0.54627 -0.28879 0.11363 0.32769 -0.38409 -0.038104 -0.70277 -0.47623 -0.29545 0.1906 1.2011 0.38105 0.24595 -0.15847 0.051696 0.71491 0.040783 -0.24121 -0.69558 0.8648 -0.18283 -0.11746 -0.058645 0.033855 -0.32785 -0.23554 -0.12762 0.088837 1.1886 0.6515 -0.32243 0.20434 -0.28283 -0.076 -0.5461 0.66366 -0.19004 0.41687 0.16786 -0.57624 0.0021248 0.038208 0.46581 0.17952 0.15208 0.77239 0.56825 1.3564 0.36707 -0.90959 -0.20369 -0.30854 0.43101 -0.62625 0.62072 -0.48968 -0.4026 0.83121 0.27788 -0.63801 -0.90269 -0.26409 0.55212 -0.21899 0.57153 0.10422 -0.23276 0.32775 0.15975 0.52786 -0.18071 -0.66116 -0.28231 -0.95566 0.32314 -0.10176 0.49961 -0.59512 0.30664 0.17566 -0.0082404 -1.2304 -0.18822 -0.094328 -0.25801 0.07948 0.59872 -0.029741 -0.14526 -0.044699 0.23121 0.20907 -0.442 0.40599 0.16151 -0.49981 0.13384 0.35293 0.034782 0.513 -0.39248 0.39123 0.28351 0.62023 0.6796 0.83006 0.48423 0.70625 -0.25091 -0.23268 0.15136 -0.35641 -0.45169 -0.071751 0.61275 0.12885 -0.62407 0.38831 -0.38358 -0.40596 0.022178 0.44976 -0.11437 -0.43881 -0.72876 -0.76978 -0.42424 0.26061 -0.83878 0.7724 -0.050794 0.0083812 0.18012 -0.77772 -0.22227 0.79349 0.3748 -0.96256 -0.97854 -0.92611 -0.65978 0.080195 -0.25126 1.1857 -0.72262 1.0632 0.50418 0.07075 -0.25384 -0.57426 -0.19791 -0.68991 0.061501 -0.17089 0.18609 -0.78265\n",
      "\n",
      "305\n",
      "209833\n",
      ". . 0.035974 -0.024421 0.71402 -0.61127 0.012771 -0.11201 0.16847 -0.14069 -0.053491 -0.87539 -0.13959 0.29731 0.072308 -0.084514 -0.1879 0.12358 0.37639 -0.39238 -0.01111 -0.04924 0.63649 0.058814 0.19076 -0.20828 -0.11036 0.14934 0.24667 -0.39438 0.22853 -0.11201 0.33539 -0.32929 -0.049727 -0.090764 0.29095 0.27504 0.22802 -0.15616 0.37302 0.3752 -0.3677 0.1518 -0.27551 -0.63281 -0.31298 -0.22441 -0.15435 -0.64802 0.28404 0.12356 0.0034255 0.03094 0.35345 -0.46781 0.59203 -0.17966 0.27702 -0.46738 0.19438 0.21939 -0.36743 -0.084781 0.03253 -0.51323 -0.55466 0.49585 0.066985 0.47906 -0.25118 0.011123 0.15605 -1.0761 0.60875 -0.15764 0.066122 0.12779 -0.089209 0.4311 0.045732 -0.29364 -0.19994 -0.065952 0.26236 0.34039 -0.4956 -0.41187 0.055566 -0.69902 -0.057696 0.76519 0.2018 -0.34497 -0.22707 0.34316 -0.16098 0.42469 0.0080257 -0.33017 -0.43485 0.23581 -0.71085 0.27985 -0.31261 -0.012817 0.48305 -0.75151 -0.02347 -0.39653 -0.86857 0.2877 0.26678 0.22291 -0.1736 -0.12782 0.35032 0.27365 0.28287 0.093409 -0.18104 -0.088499 0.1189 0.026563 -0.027942 0.17254 -0.032427 -0.10745 -0.30334 -0.096047 -0.45369 -0.12113 0.06388 -0.31841 0.0059388 0.17693 -0.21071 -0.6171 0.0018674 0.27296 0.18762 -0.060409 0.5949 0.13994 -0.25773 0.20023 0.4918 0.010659 0.046456 0.4339 -0.10386 0.021517 -0.42845 -0.25458 -0.1307 0.28307 -0.27127 0.080445 -0.31285 -0.12807 0.71382 -0.086474 -0.35553 0.65281 -0.33706 0.38617 -0.12551 0.0056478 0.10091 -0.3638 -0.033486 0.32146 -0.28719 -0.24936 0.65761 0.24376 -0.068703 0.35459 0.080304 -0.30996 -0.20199 0.31482 0.15092 -0.25125 0.76149 -0.33679 -0.079472 -0.04 -0.024693 -0.55248 0.38834 0.14696 0.50003 -0.1377 0.20994 -0.53022 -0.23712 0.24392 0.29524 -0.20951 0.11347 0.16736 -0.057263 0.20945 -0.49785 0.22321 -0.24234 -0.076378 0.42953 0.71138 0.12599 -0.1331 -0.13823 -0.22315 -0.17269 0.43008 -0.34042 -0.23127 0.66599 0.15312 0.47323 -0.28108 0.097872 -0.33014 -0.068678 0.57197 0.099838 -0.6237 -0.22572 -0.59751 -0.30157 -0.1239 0.0057373 -0.058747 -0.030736 -0.10812 0.17601 0.26234 0.15636 -0.19436 -0.097775 0.15462 -0.083865 -0.15106 0.27862 0.28175 -0.27084 0.029867 0.082898 0.020298 0.35015 -0.027691 -0.010642 0.21173 0.090988 0.59747 0.12784 -0.31951 0.26881 -0.41771 -0.2073 -0.077332 -0.32069 -0.020763 -0.24735 -0.23254 -0.005691 -0.088722 -0.13886 -0.16886 -0.13215 -0.17242 -0.1223 -0.24484 0.1374 0.24458 -0.1688 0.64932 0.051973 -0.30896 0.1567 0.351 0.081668 -0.60955 -0.54647 -0.61302 -0.48092 0.22664 -0.27639 0.12523 -0.1358 0.3322 0.54997 -0.068345 0.07199 -0.11543 0.19326 -0.085861 -0.1098 0.034066 -0.072258 -0.58648\n",
      "\n",
      "302\n",
      "220779\n",
      ". . . . 0.033459 -0.085658 0.27155 -0.56132 0.60419 -0.027276 -0.093992 0.068236 -0.3961 -0.83028 0.17456 0.46373 0.13719 0.25598 -0.33885 0.18365 0.44451 -0.8193 -0.081032 -0.070653 0.11253 -0.0087314 0.45494 -0.13481 -0.19651 -0.0098954 0.34683 -0.010663 -0.10555 -0.027425 0.46831 -0.29624 0.0027633 -0.18621 0.32282 0.20276 0.5976 -0.15331 0.52121 0.59813 -0.28581 -0.23798 -0.078883 -0.64561 0.03057 0.28304 0.15654 -0.18034 0.48116 0.39754 0.2106 -0.039421 -0.31166 0.38636 0.64125 -0.52607 0.064417 -0.23567 0.37243 -0.089502 -0.39855 -0.12211 0.37331 -0.45538 -0.40342 0.65258 0.14624 0.3247 -0.41644 0.15981 0.092788 -0.47863 0.64507 -0.013909 0.21356 0.39679 0.52347 0.16871 -0.017134 -0.57287 -0.47366 0.30996 -0.32248 -0.11949 -0.48315 -0.20478 0.45759 -1.0443 -0.58684 0.58544 -0.081284 -0.21224 -0.25302 0.90371 -0.20399 0.65895 -0.11742 -0.13352 -0.091149 0.11375 -0.18618 0.098569 -0.2067 -0.22156 -0.1557 -0.7965 -0.23144 -0.31047 -0.46223 0.26712 0.31644 -0.066401 -0.40895 0.11665 0.50156 0.47769 -0.075403 -0.482 0.033416 0.17506 -0.063225 0.19088 0.039387 0.2396 -0.35331 -0.09274 -0.33705 0.085312 0.080227 -0.020173 0.507 -0.072361 0.13175 -0.45573 0.20334 -0.056897 -0.11733 0.047485 0.016908 -0.24814 0.71598 -0.055958 0.37822 0.3392 0.17434 -0.37932 0.03775 0.019235 -0.29447 -0.18964 -0.45798 -0.16 -0.056206 0.042038 0.64842 0.47592 -0.67641 -0.57816 0.769 -0.096332 -0.064562 0.042617 -0.23167 0.51994 0.10079 0.15415 -0.14515 -0.21889 0.23307 -0.043176 -0.41485 0.1427 0.84153 -0.078821 0.060877 0.12004 -0.26696 -0.53933 -0.36731 -0.37563 -0.35086 -0.24055 0.49705 -0.34699 0.021831 0.53459 0.2906 -0.065185 -0.19822 0.33217 0.28218 0.34624 0.36723 -0.66741 0.082508 -0.10312 0.27671 -0.55848 0.67853 0.040049 -0.0057962 0.86106 -0.40337 -0.45425 -0.48904 -0.11567 0.71084 -0.00071633 -0.075139 0.29584 -0.38594 0.17853 0.033168 0.19186 -0.10717 -0.51614 0.19278 -0.43339 0.51961 0.10363 0.28009 -0.41613 0.34869 0.052315 -0.026509 -0.64101 -0.047879 -0.42739 -0.018592 0.18577 -0.16994 -0.18489 -0.076386 -0.28981 0.26335 0.21274 0.11926 -0.32697 0.22216 -0.24976 0.36953 0.24742 0.37245 0.37218 -0.18512 -0.23093 0.035941 0.2418 0.058993 0.16378 0.43893 0.19057 -0.15457 0.17481 -0.30859 -0.1335 0.21542 -0.44562 0.48477 0.28185 -0.063253 0.053603 -0.05103 -0.29387 0.17704 0.64601 -0.11012 -0.23288 -0.60988 -0.33054 -0.25336 -0.042175 -0.43281 -0.061033 -0.097728 0.42459 0.051169 -0.37042 0.053402 0.18471 0.37567 -0.66422 -0.2099 -0.92126 -0.098194 0.034713 0.19768 0.35687 -0.03349 0.72838 0.1016 -0.42271 -0.19997 -0.21866 -0.2066 -0.59319 -0.052248 -0.032041 0.068443 -0.92476\n",
      "\n",
      "304\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "f = open(os.path.dirname(os.getcwd()) + '/models/glove.840B.300d.txt')\n",
    "count = 0\n",
    "for line in f:\n",
    "    l = line.split()\n",
    "    coe = l[1:]\n",
    "    for c in coe:\n",
    "        if c == '.':\n",
    "            print (count)\n",
    "            print (line)\n",
    "            print (len(l))\n",
    "        break\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,f = x(7,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it is a call for artistic freedom , but interestingly enough , this political film shies away from offering any significant political commentary . a performance artist eats a bar of soap with a knife and fork and is revolted by what he eats , almost as much as the audience is revolted by seeing him go through that routine . this was a hard scene to swallow as not being a contrived one and a very forced metaphor on the political situation , though it provided some much needed levity rather than any particular increase in political insights . the last 20 minutes of the film offers a surprise twist to the story and thereby saves it somewhat from the doldrums it was in . it results in a film that gets its message across that freedom is frozen in china , that things are still far from democratic . it was a though-provoking film , but in a very manipulative way , that was none too pleasing to view despite its good intentions .',\n",
       " 'steal this movie ! it meant well , showing the charismatic abby in the best possible light as the \\'60s prankster symbol of anarchistic , ecstatic , anti-establishment revolution , but this clich ? biopic failed to be emotionally involving , it had no craziness to it . . . and . . . its false sense of piety to its subject ruined the whole point of the film . i read hoffman\\'s steal this book ! the film , adapted from two books -- abbie and anita hoffman\\'s \" to america with love : letters from the underground \" and marty jezer\\'s \" abbie hoffman : american rebel , \" was two goody-goody in its approach to capture either the mood of the changing times or the manic-depressive mood swings of the unabashed publicity hound , who thought of himself as a hippie organizer . admittedly , making a film about the \\'60s ( in this film abbie\\'s starry-eyed days were between 1967-70 ) is not easy to do because of the problem of making a satire about what was a satire to begin with , but this film was so poorly scripted , directed and acted , that it is worst than most films about that era . d\\'onofrio who is a big man does not physically resemble the much smaller hoffman and his odd boston accent sounded artificial . he does bring an energy to the role , but it seems misplaced as he seems to have made the one thing abbie had going for him , a real sense for comedy and wit , seem nonexistent , as the script is so self-serving to him and his lawyer , that it made the whole project stink . the only thing d\\'onofrio does well , is try and steal this movie for himself . all the other roles were flatly played and had no impact on the film .',\n",
       " \"a rather flat film noir that never gets that interesting . it's the simpleness of this tale and lack of any pretensions that makes it convincing but not necessarily sparkling .\",\n",
       " 'takeshi \" beat \" kitano is certainly a unique director , whose absurdist style of filmmaking is readily recognizable , achieving auteur status . he has a fascination with gangsters , violence , and in presenting his quirky black humor in a most compelling way . his films are always visually startling , with a bevy of bizarre shots , and , so far , all his films have gotten away with a mindless but intriguing storyline . he is so fascinating to watch , that it is shame we couldn\\'t see more of his lunacy ; instead , the supporting cast , funny as they are with their deadpan humor , nevertheless , they cannot carry the film , and kitano has chosen to center the film around them . fortunately , there are plenty of his usual visual treats in this film , that make the film seem special anyhow . kitano , also , relishes giving women roles that could be considered demeaning . though it is sickeningly amusing to see how rough-shod he treats them in so callous and an ungentlemanly manner , that one might be caught ruefully laughing at them getting dumped on and treated as garbage , and supposedly liking it and coming back for more , it still shows that he doesn\\'t really know how to portray women on screen . maybe he knows something i don\\'t know . but there is never any romance in his films that amount to anything , and this film is no exception . this mindless act escalates on both sides , and , of course , it makes no sense . this is all casually done , as if this kind of mayhem was as natural as eating rice cakes . if there is any point to this story , and i am not sure there is , but the message here might be , that friends are needed to help you out , no one is immune from the insanity that is in the air , because according to kitano , insanity is catching . and , if taking a stand alone against many , you are in deep trouble . somehow this visual feast of a film was strangely appealing and original in all aspects of filmmaking . so let me say bravo to the one time stand-up comedian who doesn\\'t know how to make a safe film , and tip my eagle baseball hat to him , not only for hitting a home run , but showing that one can hit a home run but not score the needed winning run by running past the man who was on base . a cult film delight as a cruel form of entertainment , that is not for all tastes , naturally . incidently , the american title to the film , boiling point , is misleading : in japanese the title refers in slang to a baseball score .',\n",
       " 'as the one giving the orders , the big boss , he is a less portly version of sydney greenstreet , playing the type of role once reserved for the mirthful greenstreet . don\\'t ask too much more about the plot , it is not particularly pertinent , and some explanations about what this film is about , were obviously snipped off at the cutting room . but an unclear story and poor dubbing quality of most of the non-english speaking actors , does not really hamper the absurdity presented on screen , because it is done in such a way , that it defies any critical commentary , having a dark humor about it that is funnier than hell . chabrol has gone to absurd extremes of humor in this commercially driven screwball comic/mystery , that has the agents working for the greek government , at least i think that is who they are working for . the one in charge of them , is a lazy , sleazy , and mediocre bureaucrat , named sharp ( bouquet ) , aptly named because he is a dull wit , who is clueless about what is going on , as he confronts the two agents working for him , the imaginative but usually wrong , robert , and the more steady dex ( ronet ) , who like sharp , has his eye on robert\\'s appealing wife , shanny , only he doesn\\'t get his face slapped like sharp does by her , as sharp makes too much of an overt pass at her . jean seberg , the much maligned actress , is just terrific in this breezy role , showing a certain amount of vulnerability and courage and sex appeal , and an eye for comic timing , as she takes over for robert when he is killed just before he was going to tell her the info he has about the black boxes , and they were to celebrate the news with champagne and love making . the road to corinthe , the european title for the film , is the road to the marble foundry owned by kalhides . it is the place where there is this great mix of intrigue and murder and comedy , as the black boxes are discovered there , hidden in the statues\\' heads , and as kalhides says , if you think i\\'m not imaginative enough to put them someplace else , you are wrong , because some of them i have put in the base of the statue . it is a wonderful b movie experience , that rips deliciously into the spy film genre and comes away with a bundle of laughs for all its awkwardness and a ridiculous ending to a story that fails to make much sense . i think chabrol hit it best , when the opening epigraph states , \" i do not ask you to believe it , but i suggest that you dream about it . \" well , maybe , you don\\'t want to dream about it , but if you daydream about it during the time of day when you are a little bored with things or upset over something , the absurdity of this film should bring a smile to you .',\n",
       " 'ghost dog is the seventh feature film , of arguably america\\'s most innovative and underrated director , jim jarmusch . i consider it a shame that one of america\\'s best directors had to get european backers for this film and still receives a better reception abroad than he does in his own country . she then says in a low voice , \" you can have it . i\\'m finished with it . \" when louie flinches , he says it is better than if we murder you . there is comedy here in the absurdity of the situation even though no one cracks a joke . but , one of the points of the story , is that things that happen don\\'t necessarily make sense , they just happen . reading books is readily accepted by both parties as something that is cool . the assumption is that they both have soul and can talk the black man\\'s rap . the film is much influenced by jean-pierre melville\\'s stylized 1967 gangster masterpiece le samurai , which also quotes an ancient japanese ideology that influenced its hero , though in that film , it is from the book of bushido , which is a fictional work . ghost dog remains for the most part a parody of other movie characters . the film is slow-paced due to the stoppage to read from the excerpts from the hagakure texts by whitaker . it is a movie that is mostly invigorated by forest whitaker\\'s stunning performance of a man who is an icon , who lives by myth alone , whose most memorable statement , is that \" the end is important in all things . \" the most glaring error ghost dog makes , is in his strictly literal interpretation of what he is supposed to do as a samurai warrior . that would have been the true way of a samurai warrior , whose lessons are meant for battle and seem to be easily misinterpreted by someone living so cut off from human contact and without the benefit of a teacher . jarmusch has in all his films displayed an interest of seeing how another culture looks at the american culture , having already shown how hungarians , native americans , and japanese react to seeing america . it now seems to be the turn of the black man , as this film is basically about the forest whitaker character making peace with who he is , and showing that to be an american , it takes more than one culture to influence you , whether it\\'s the mafia men absorbed by cartoons or rap music or poetry , or the director himself , influenced to be a so-called \" hip \" white negro . for jarmusch , america is an exotic place where different cultures uniquely flourish in the most unexpected spots . the shining points of the film come from the moving cinematography of robby muller , the minimalist mise-en-sc ? ne , the splendid expressive performance by forest whitaker , the underlying humor , and the freshness of jarmusch\\'s approach to filmmaking , proving that he is someone willing to take chances . there are critics who constantly rave about less cutting-edge films more than do about ones that are not afraid to mess with set-concepts . for this film , they offer mostly faint and lefthanded praises . as for me , i\\'ll take my chances with heaping praise on a jarmusch near-miss like this one , over so many other forgettable praiseworthy hits that are so limited in scope . jarmusch\\'s first language is poetry and it is my belief that this film is as close to a lyrical masterpiece as a film can be without being one . its weakest point being a lack of character development for the mafia figures , as the mafia characters were more cartoonish than real , they seemed to be created to fit a certain standard mold rather than to be developed out of their own personalities . but that flaw , was also what drove the film comically , therefore making that weakness more palatable and understandable . this film is similar in mood to his other ambitious work , which was a masterpiece , dead man , and it is one that makes so many fine points to justify its wide range of themes . it is foolish to try and tightly categorize it , except to say that even though it is not exactly a mainstream film , neither is it primarily an art-house film . it just might be one of those intriguing films that requires an acquired taste and once acquired , leaves no doubt about how good it is , no matter that there are a few things in it that might be considered tasteless .',\n",
       " 'kluger is perceived as being tougher and smarter than the d . a . the final shoot-out is well executed and though the story is as plain as vanilla , it still had plenty of tough action . felix e . feist directed this tough b&w noir film in a gritty and pleasing style .',\n",
       " 'fast-paced action and witty one-liners , allow this hitchcock-like story to be both amusing and thrilling . and the surprise ending is a beaut , which should catch you off-guard , as you will most likely be misled and unable to guess who the murderer is . jolly good fun . a real delightful and snappy film , featuring mystery , humor , snappy dialogue , and a great surprise ending .',\n",
       " \"it asks the question , how would you react in finding out that your world is not real ? this is a theme a number of '90s sci-fi films have already done . it seems as if the movies are running out of ideas for this world and need the after-life for more material . supposedly , i am being prepared for a film that will make me think . instead , what i got was a sci-fi film that left me somewhat confused by its being both a murder mystery and a time travel sci-fi'er . it was very difficult to keep track of what was going on , as the film moved back and forth between two different time frames . it was also difficult for me to grok what is meant by the creation of parallel dimensions and how it is possible for our world to be a copy of another . what made it even more difficult , was that the story line was built around the murder case and not around the more interesting ideas generated by time travel . yet , it was this virtual reality computerized world that left me dazzled with its engrossing ideas . though the film tried , it simply couldn't create too much depth for its characters . they remained tied to the sci-fi part of the story . they performed their task well , but their characters couldn't expand because of the limitations they were presented with . they just didn't have too much sparkle to them . even the romance between the leads was jejune . this proved to be a fatal flaw in the film . these creations have feelings and emotions just like people ; but they don't know they're not real . it is too dangerous . yes . the 13th floor , directed by josef rusnak from a screenplay he wrote with ravel centeno-rodriguez can be valued for its re-creation of a 1937 los angeles of fancy bars , booming oil wells , and a magnificent wilshire boulevard setting . all this ostentation taking place in the middle of our great depression . it was fun to see this opulent depiction of a town that was to only grow more opulent and depressed in the future . in this most original story , it seems hannon has made one too many simulations himself and now wants to abort this project . i got mixed messages from this film . i thought it was an interesting concept , that somehow didn't seem as exciting as it should be on the first viewing . i will reserve final judgment on it , since i think it could look better upon seeing it again . as for the flatness of the characters , that i'm afraid won't change . but i must say , i thought the actors did a really fine job considering the limitations placed on them by the script . . . also , the filmmakers did a good job with their use of costume and set designs . i wanted to like this film more than i actually did , but i couldn't fully enjoy it , for the simple reason that too much of the film was taken up by the uninteresting murder case .\",\n",
       " 'this is a pointless b- film actioner , a remake of the gritty 1971 british noir classic directed by mike hodges , which had the good fortune to have michael caine be the star and to have a story with an edge to it . this \" get carter \" features mindless violence , an incoherent and uninvolving story , and most unfortunately the humorless presence of the miscast stallone as a vegas mob enforcer , going to seattle for the funeral of his bartender brother he hasn\\'t seen for a long time . he is dressed in a tacky bright blue suit , sports a goatee , and speaks in a low voice . it is filmed amid some dazzling night shots of las vegas casinos and shots of a rainy seattle , though the rain has no effect on stallone\\'s suit , it never gets soaked no matter how much he exposes it to the elements . it\\'s a clich ? movie . . . so predictable , that if you didn\\'t want to see the way the sleazy bad guys were going to get payback for what they did , you could have left the theater and figured out which way this macho stylish film was going by yourself . you would have missed nothing , there is absolutely nothing interesting about this film . it seems that stephen kay has taken a perfectly taut original film , which was nasty and unremitting to the core , and made a mess of the remake by trying to clean it up , making it into a sleazy film , nevertheless , but one with no redeeming features . he tries to give the film a moment of acting , hugging his niece in a warm embrace , as behind her back he grimaces with obvious pain on his teary face , assuring the audience to pay little attention to this human gesture , they shouldn\\'t worry , he hasn\\'t gone soft , there\\'s going to be a payback . the most disgusting role in the film is reserved for \" gazillionaire \" computer geek alan cumming , he is the simpering coward , the most unmanly and therefore the most unseemly one in the film . it could have been built as the battle between the sleaze champ vs . the egomaniac . it\\'s an undeveloped role , but caine is so good at getting credibility for his character , someone who pretends to have nothing to gain from the murder , who could therefore be honest about what happened , but is , of course , somehow involved in the cover-up . there are several other sleazes around , who have various things to add to the story , such as more gratuitous violence and a seamy look at their lives . since carter fails to heed such warnings , these two will clash in seattle . anyway , no minor b-thriller should be without such a car chase . the only positive spin i could put on this morose work , is to say that it could have been a lot worse , stallone could have talked in a loud voice . this is just another in a long list of films since the 1980s to try and resurrect sylvester stallone\\'s \" comeback . \" this picture won\\'t do . it lacks whatever suspense , character development , and ability to involve the viewer , that is needed . it only features the ego of stallone plodding his way in a shallow story . if you want to see \" get carter , \" rent the 1971 video . it\\'s a nasty story , but it holds together in purpose and credibility , catching hold of the downtrodden newcastle atmosphere in a subtle way , something this film was never able to realize for seattle .']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glove_dl20 as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, embedding_matrix, padded_docs = gd.get_glove_m(xtrain_d, ytrain_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17911"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.27085999,  0.044006  , -0.02026   , ..., -0.4923    ,\n",
       "         0.63687003,  0.23642001],\n",
       "       ..., \n",
       "       [ 0.49579999, -0.41578001,  0.19389001, ..., -0.30579001,\n",
       "         0.45275   ,  0.76160002],\n",
       "       [-0.46489999, -1.06060004, -0.10805   , ...,  0.036301  ,\n",
       "        -0.85459   ,  0.29347   ],\n",
       "       [-0.032544  ,  0.093303  ,  0.0076568 , ...,  0.63237   ,\n",
       "         0.43331   ,  0.84724998]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_padded_docs = gd.padded_doc(xvalid_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4, 100)            1791100   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,791,501\n",
      "Trainable params: 401\n",
      "Non-trainable params: 1,791,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f762c88>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, ytrain_d, epochs=50, verbose=0)\n",
    "# # evaluate the model\n",
    "# loss, accuracy = model.evaluate(x_test_padded_docs, yvalid_d, verbose=0)\n",
    "# print('Accuracy: %f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d_glv = np.array(xtrain_d_glv)\n",
    "xvalid_d_glv = np.array(xvalid_d_glv)\n",
    "xtrain_d_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 300\n",
    "def model_3_layer():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation = 'relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "#     model.compile(optimizer='rmsprop', \n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "    model.compile(optimizer='rmsprop', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    print ('compile done')\n",
    "    return model\n",
    "\n",
    "def fit_model(model, X, y):\n",
    "    model.fit(X,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 286,211\n",
      "Trainable params: 286,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n"
     ]
    }
   ],
   "source": [
    "model = model_3_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 739 samples, validate on 185 samples\n",
      "Epoch 1/10\n",
      "739/739 [==============================] - 1s 1ms/step - loss: 0.6900 - acc: 0.6978 - val_loss: 0.6874 - val_acc: 0.7027\n",
      "Epoch 2/10\n",
      "739/739 [==============================] - 0s 276us/step - loss: 0.6854 - acc: 0.7032 - val_loss: 0.6833 - val_acc: 0.7027\n",
      "Epoch 3/10\n",
      "739/739 [==============================] - 0s 239us/step - loss: 0.6813 - acc: 0.7032 - val_loss: 0.6792 - val_acc: 0.7027\n",
      "Epoch 4/10\n",
      "739/739 [==============================] - 0s 269us/step - loss: 0.6773 - acc: 0.7032 - val_loss: 0.6753 - val_acc: 0.7027\n",
      "Epoch 5/10\n",
      "739/739 [==============================] - ETA: 0s - loss: 0.6735 - acc: 0.700 - 0s 282us/step - loss: 0.6734 - acc: 0.7032 - val_loss: 0.6715 - val_acc: 0.7027\n",
      "Epoch 6/10\n",
      "739/739 [==============================] - 0s 274us/step - loss: 0.6695 - acc: 0.7032 - val_loss: 0.6678 - val_acc: 0.7027\n",
      "Epoch 7/10\n",
      "739/739 [==============================] - 0s 356us/step - loss: 0.6658 - acc: 0.7032 - val_loss: 0.6642 - val_acc: 0.7027\n",
      "Epoch 8/10\n",
      "739/739 [==============================] - 0s 379us/step - loss: 0.6623 - acc: 0.7032 - val_loss: 0.6609 - val_acc: 0.7027\n",
      "Epoch 9/10\n",
      "739/739 [==============================] - 0s 296us/step - loss: 0.6589 - acc: 0.7032 - val_loss: 0.6575 - val_acc: 0.7027\n",
      "Epoch 10/10\n",
      "739/739 [==============================] - 0s 292us/step - loss: 0.6556 - acc: 0.7032 - val_loss: 0.6543 - val_acc: 0.7027\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, xtrain_d_glv, ytrain_d_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_gl.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove_nn on the other writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/id.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "# label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"3class_label\"])\n",
    "\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.4class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/rating.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "james = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "james[\"strongly neg\"]=james.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "james[\"strongly pos\"]=james.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "james['n']=james.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "y_j_encode = james[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = james.subj_extraction.values\n",
    "y_j = james['3class_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_j, xvalid_j, ytrain_j, yvalid_j = train_test_split(x_j, y_j, \n",
    "                                                  stratify=y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_j, xvalid_j, ytrain_j_encode, yvalid_j_encode = train_test_split(x_j, y_j_encode, \n",
    "                                                  stratify=y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 300)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_j_glv = [g.sentence_vectorize(sent) for sent in xtrain_j]\n",
    "xvalid_j_glv = [g.sentence_vectorize(sent) for sent in xvalid_j]\n",
    "xtrain_j_glv = np.array(xtrain_j_glv)\n",
    "xvalid_j_glv = np.array(xvalid_j_glv)\n",
    "\n",
    "xtrain_j_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the pre_trained model and evaluate on james directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 73.79%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model_gl.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_gl.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(xvalid_j_glv, yvalid_j_encode, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit 3 layer-nn on james"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 286,211\n",
      "Trainable params: 286,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n"
     ]
    }
   ],
   "source": [
    "model = model_3_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 940 samples, validate on 236 samples\n",
      "Epoch 1/10\n",
      "940/940 [==============================] - 0s 295us/step - loss: 0.6486 - acc: 0.7379 - val_loss: 0.6466 - val_acc: 0.7401\n",
      "Epoch 2/10\n",
      "940/940 [==============================] - 0s 283us/step - loss: 0.6430 - acc: 0.7379 - val_loss: 0.6408 - val_acc: 0.7401\n",
      "Epoch 3/10\n",
      "940/940 [==============================] - 0s 266us/step - loss: 0.6378 - acc: 0.7379 - val_loss: 0.6351 - val_acc: 0.7401\n",
      "Epoch 4/10\n",
      "940/940 [==============================] - 0s 290us/step - loss: 0.6328 - acc: 0.7379 - val_loss: 0.6298 - val_acc: 0.7401\n",
      "Epoch 5/10\n",
      "940/940 [==============================] - 0s 275us/step - loss: 0.6280 - acc: 0.7379 - val_loss: 0.6245 - val_acc: 0.7401\n",
      "Epoch 6/10\n",
      "940/940 [==============================] - 0s 284us/step - loss: 0.6232 - acc: 0.7379 - val_loss: 0.6192 - val_acc: 0.7401\n",
      "Epoch 7/10\n",
      "940/940 [==============================] - 0s 293us/step - loss: 0.6185 - acc: 0.7379 - val_loss: 0.6143 - val_acc: 0.7401\n",
      "Epoch 8/10\n",
      "940/940 [==============================] - 0s 292us/step - loss: 0.6140 - acc: 0.7379 - val_loss: 0.6094 - val_acc: 0.7401\n",
      "Epoch 9/10\n",
      "940/940 [==============================] - 0s 327us/step - loss: 0.6097 - acc: 0.7379 - val_loss: 0.6047 - val_acc: 0.7401\n",
      "Epoch 10/10\n",
      "940/940 [==============================] - 0s 261us/step - loss: 0.6055 - acc: 0.7379 - val_loss: 0.6001 - val_acc: 0.7401\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, xtrain_j_glv, ytrain_j_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x12ca334e0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 940 samples, validate on 236 samples\n",
      "Epoch 1/10\n",
      "940/940 [==============================] - 1s 1ms/step - loss: 0.6473 - acc: 0.7379 - val_loss: 0.6486 - val_acc: 0.7401\n",
      "Epoch 2/10\n",
      "940/940 [==============================] - 0s 244us/step - loss: 0.6468 - acc: 0.7379 - val_loss: 0.6480 - val_acc: 0.7401\n",
      "Epoch 3/10\n",
      "940/940 [==============================] - 0s 274us/step - loss: 0.6463 - acc: 0.7379 - val_loss: 0.6474 - val_acc: 0.7401\n",
      "Epoch 4/10\n",
      "940/940 [==============================] - 0s 268us/step - loss: 0.6457 - acc: 0.7379 - val_loss: 0.6469 - val_acc: 0.7401\n",
      "Epoch 5/10\n",
      "940/940 [==============================] - 0s 294us/step - loss: 0.6452 - acc: 0.7379 - val_loss: 0.6463 - val_acc: 0.7401\n",
      "Epoch 6/10\n",
      "940/940 [==============================] - 0s 281us/step - loss: 0.6446 - acc: 0.7379 - val_loss: 0.6457 - val_acc: 0.7401\n",
      "Epoch 7/10\n",
      "940/940 [==============================] - 0s 261us/step - loss: 0.6441 - acc: 0.7379 - val_loss: 0.6452 - val_acc: 0.7401\n",
      "Epoch 8/10\n",
      "940/940 [==============================] - 0s 284us/step - loss: 0.6436 - acc: 0.7379 - val_loss: 0.6446 - val_acc: 0.7401\n",
      "Epoch 9/10\n",
      "940/940 [==============================] - 0s 277us/step - loss: 0.6431 - acc: 0.7379 - val_loss: 0.6440 - val_acc: 0.7401\n",
      "Epoch 10/10\n",
      "940/940 [==============================] - 0s 290us/step - loss: 0.6426 - acc: 0.7379 - val_loss: 0.6435 - val_acc: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1292176a0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.fit(xtrain_j_glv, ytrain_j_encode, batch_size=32,epochs=10,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn on glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128,5,\n",
    "                 activation='relu'))\n",
    "    model.add(MaxPooling1D(5))\n",
    "    model.add(Conv2D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 300\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 100\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000,\n",
    "                    400,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(xtrain_j_glv, ytrain_j_encode,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(xvalid_j_glv, yvalid_j_encode))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
