{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "# ## Plotly\n",
    "# import plotly.offline as py\n",
    "# import plotly.graph_objs as go\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.3class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.4class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/rating.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1027, 5)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dennis = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "dennis = dennis.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "dennis[\"strongly neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "dennis[\"strongly pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "dennis['n']=dennis.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "y_d_encode = dennis[['n', 'neg', 'pos']]\n",
    "x_d = list(dennis['subj_extraction'])\n",
    "x_d_padded = gd.padded_doc(x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_d_padded, xvalid_d_padded, ytrain_d, yvalid_d = train_test_split(x_d_padded, y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_d_padded, xvalid_d_padded, ytrain_d_encode, yvalid_d_encode = train_test_split(x_d_padded, y_d_encode,\n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1027, 3000)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d_padded.shape\n",
    "x_d_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glove_dl23 as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, embedding_matrix, padded_docs = gd.get_glove_m(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.1529    , -0.24279   ,  0.89837003, ..., -0.59100002,\n",
       "         1.00390005,  0.20664001],\n",
       "       ..., \n",
       "       [-0.86329001,  0.63463998, -0.33840999, ..., -0.052484  ,\n",
       "         0.20648   ,  0.46869999],\n",
       "       [ 0.19193999,  0.38505   , -0.22404   , ..., -0.16169   ,\n",
       "         0.080152  ,  0.29284999],\n",
       "       [-0.045712  ,  0.14199001, -0.30963001, ..., -0.22722   ,\n",
       "         0.76585001,  0.66973001]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with glove weights, shape (41441, 100)\n",
      "Epoch 1/10\n",
      "924/924 [==============================] - 21s 23ms/step - loss: 1.0877 - acc: 0.3983\n",
      "Epoch 2/10\n",
      "924/924 [==============================] - 19s 21ms/step - loss: 1.0867 - acc: 0.4177\n",
      "Epoch 3/10\n",
      "924/924 [==============================] - 19s 21ms/step - loss: 1.0761 - acc: 0.4113\n",
      "Epoch 4/10\n",
      "924/924 [==============================] - 19s 21ms/step - loss: 1.0756 - acc: 0.4123\n",
      "Epoch 5/10\n",
      "924/924 [==============================] - 19s 21ms/step - loss: 1.0578 - acc: 0.4145\n",
      "Epoch 6/10\n",
      "924/924 [==============================] - 20s 21ms/step - loss: 1.0721 - acc: 0.4242\n",
      "Epoch 7/10\n",
      "924/924 [==============================] - 19s 21ms/step - loss: 1.0365 - acc: 0.4297\n",
      "Epoch 8/10\n",
      "924/924 [==============================] - 20s 21ms/step - loss: 1.0330 - acc: 0.4318\n",
      "Epoch 9/10\n",
      "924/924 [==============================] - 19s 21ms/step - loss: 1.0222 - acc: 0.4426\n",
      "Epoch 10/10\n",
      "924/924 [==============================] - 19s 21ms/step - loss: 1.0076 - acc: 0.4361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15217f710>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "def build_model(embedding_matrix, vocab_size):\n",
    "    # define model\n",
    "    embedding_dim = 50\n",
    "    filter_sizes = (2, 4)\n",
    "    num_filters = 10\n",
    "    dropout_prob = (0.5, 0.8)\n",
    "    hidden_dims = 50\n",
    "\n",
    "    # Build model\n",
    "    sequence_length = 3000\n",
    "    input_shape = (sequence_length,)\n",
    "\n",
    "    model_input = Input(shape=input_shape)\n",
    "\n",
    "    # Static model does not have embedding layer\n",
    "\n",
    "    z = Embedding(vocab_size, 100, input_length=sequence_length,weights=[embedding_matrix], name=\"embedding\")(model_input)\n",
    "    z.trainable = False\n",
    "    \n",
    "    z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "    # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = Convolution1D(filters=num_filters,\n",
    "                             kernel_size=sz,\n",
    "                             padding=\"valid\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1)(z)\n",
    "        conv = MaxPooling1D(pool_size=1)(conv)\n",
    "        conv = Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "    z = Dropout(dropout_prob[1])(z)\n",
    "    z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "    model_output = Dense(3, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    weights = np.array([v for v in embedding_matrix])\n",
    "    print(\"Initializing embedding layer with glove weights, shape\", weights.shape)\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights([weights])\n",
    "    return model\n",
    "\n",
    "# # Initialize weights with word2vec\n",
    "# if model_type == \"CNN-non-static\":\n",
    "#     weights = np.array([v for v in embedding_weights.values()])\n",
    "#     print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "#     embedding_layer = model.get_layer(\"embedding\")\n",
    "#     embedding_layer.set_weights([weights])\n",
    "\n",
    "# Train the model\n",
    "model = build_model(embedding_matrix, vocab_size)\n",
    "model.fit(xtrain_d_padded, ytrain_d_encode, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0518304422063736, 0.40776699115929094]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xvalid_d_padded, yvalid_d_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 400, 100)     1791100     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 100)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 399, 10)      2010        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 397, 10)      4010        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 399, 10)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 397, 10)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3990)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3970)         0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7960)         0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7960)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           398050      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            153         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,195,323\n",
      "Trainable params: 2,195,323\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.predict(xtrain_d_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visuliaze the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.747573\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(xvalid_d_padded_docs, yvalid_d_encode, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d_glv = np.array(xtrain_d_glv)\n",
    "xvalid_d_glv = np.array(xvalid_d_glv)\n",
    "xtrain_d_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_gl_cnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove_nn on the other writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/id.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "# label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"3class_label\"])\n",
    "\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.4class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/rating.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "james = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "james['n']=james.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "y_j_encode = james[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = james['subj_extraction']\n",
    "y_j = james['3class_label']\n",
    "x_j_padded = gd.padded_doc(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_j_padded, xvalid_j_padded, ytrain_j, yvalid_j = train_test_split(x_j_padded, y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1307, 3000)\n",
      "(1307,)\n"
     ]
    }
   ],
   "source": [
    "print (x_j_padded.shape)\n",
    "print (y_j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_j_padded, xvalid_j_padded, ytrain_j_encode, yvalid_j_encode = train_test_split(x_j_padded, y_j_encode, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1307, 3000)\n",
      "(1307, 3)\n",
      "(131, 3000)\n",
      "(131, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_j_padded.shape)\n",
    "print (y_j_encode.shape)\n",
    "print (xvalid_j_padded.shape)\n",
    "print (yvalid_j_encode.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the pre_trained model and evaluate on james directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "131/131 [==============================] - 2s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.732673660489439, 0.33078880187209325]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_gl_cnn.json', 'r')\n",
    "loaded_model_cnn_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_cnn = model_from_json(loaded_model_cnn_json)\n",
    "# load weights into new model\n",
    "loaded_model_cnn.load_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model_cnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "loaded_model_cnn.evaluate(xvalid_j_padded, yvalid_j_encode, verbose=1)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model_cnn.metrics_names[1], score[1]*100))\n",
    "# # loaded_model.summary()\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.82195321937183763, 0.54212456122859498]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_cnn.predict(xvalid_j_padded)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model_cnn.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuning freeze the E layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in loaded_model_cnn.layers[:2]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1518bf588>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "loaded_model_cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with glove weights, shape (41441, 100)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_15 to have shape (100,) but got array with shape (3000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-1bbf0d448338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_j_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_j_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1594\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1424\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1427\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    118\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_15 to have shape (100,) but got array with shape (3000,)"
     ]
    }
   ],
   "source": [
    "model_j = build_model(embedding_matrix, vocab_size)\n",
    "model_j.fit(xtrain_j_padded, ytrain_j_encode, epochs = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 264us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1063710202227581, 0.29670329506580645]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_j.evaluate(xvalid_j_padded, yvalid_j_encode, verbose=1)\n",
    "# model_j.evaluate(xtrain_j_padded, ytrain_j_encode, verbose=1)\n",
    "# model.metrics_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64245242,  0.50412488,  0.23868002],\n",
       "       [ 0.49703661,  0.5076555 ,  0.32914522],\n",
       "       [ 0.43550697,  0.48260731,  0.56188565],\n",
       "       [ 0.28396404,  0.61782485,  0.48895967],\n",
       "       [ 0.42587209,  0.48146808,  0.46928751],\n",
       "       [ 0.31395876,  0.61788809,  0.60919958],\n",
       "       [ 0.42675418,  0.4544012 ,  0.44078216],\n",
       "       [ 0.33290228,  0.41679204,  0.58824396],\n",
       "       [ 0.56185287,  0.46434608,  0.2707774 ],\n",
       "       [ 0.49795598,  0.41308469,  0.51998979],\n",
       "       [ 0.20698871,  0.66136622,  0.50882316],\n",
       "       [ 0.51466602,  0.50216717,  0.27823126],\n",
       "       [ 0.44028118,  0.55967009,  0.35109553],\n",
       "       [ 0.26097831,  0.52796692,  0.65655339],\n",
       "       [ 0.3712368 ,  0.62871826,  0.40809503],\n",
       "       [ 0.38964769,  0.52673215,  0.42186907],\n",
       "       [ 0.58997673,  0.38191703,  0.43637866],\n",
       "       [ 0.40669954,  0.510086  ,  0.44548333],\n",
       "       [ 0.32908437,  0.50886804,  0.58529431],\n",
       "       [ 0.19547509,  0.39568335,  0.64250672],\n",
       "       [ 0.37727225,  0.48087683,  0.37718514],\n",
       "       [ 0.39478901,  0.52949727,  0.43851447],\n",
       "       [ 0.39898074,  0.4327434 ,  0.42070082],\n",
       "       [ 0.42737365,  0.50629044,  0.43345362],\n",
       "       [ 0.50818759,  0.48961437,  0.39653158],\n",
       "       [ 0.48133478,  0.54429907,  0.26450887],\n",
       "       [ 0.26521686,  0.67649984,  0.41465876],\n",
       "       [ 0.26602092,  0.22453472,  0.72127181],\n",
       "       [ 0.32133877,  0.59859723,  0.55383021],\n",
       "       [ 0.20676987,  0.56594336,  0.57814628],\n",
       "       [ 0.54265141,  0.60604334,  0.2901457 ],\n",
       "       [ 0.31687251,  0.56634974,  0.49255884],\n",
       "       [ 0.40973189,  0.53652656,  0.33649573],\n",
       "       [ 0.42400071,  0.53237116,  0.40289247],\n",
       "       [ 0.45505053,  0.35670522,  0.45928881],\n",
       "       [ 0.46252772,  0.45802101,  0.33024731],\n",
       "       [ 0.3657957 ,  0.54580218,  0.55701661],\n",
       "       [ 0.15710877,  0.33086461,  0.83371019],\n",
       "       [ 0.41335714,  0.56914657,  0.31734747],\n",
       "       [ 0.2391534 ,  0.71218359,  0.36129257],\n",
       "       [ 0.28164387,  0.6205554 ,  0.49749562],\n",
       "       [ 0.40838048,  0.44948524,  0.45260078],\n",
       "       [ 0.55536944,  0.33078083,  0.28463084],\n",
       "       [ 0.33286768,  0.51416117,  0.5905363 ],\n",
       "       [ 0.28185543,  0.4976967 ,  0.5841735 ],\n",
       "       [ 0.46790969,  0.49561659,  0.50672764],\n",
       "       [ 0.44989645,  0.47369832,  0.46818393],\n",
       "       [ 0.44220063,  0.44035602,  0.47157341],\n",
       "       [ 0.38105848,  0.49302915,  0.41003862],\n",
       "       [ 0.37884408,  0.46824306,  0.5526672 ],\n",
       "       [ 0.18821768,  0.50193626,  0.71171844],\n",
       "       [ 0.44464362,  0.61779678,  0.3442843 ],\n",
       "       [ 0.43931088,  0.41846558,  0.28990391],\n",
       "       [ 0.17786409,  0.48591572,  0.76301122],\n",
       "       [ 0.46704736,  0.44344237,  0.31348732],\n",
       "       [ 0.20512733,  0.6902653 ,  0.50583303],\n",
       "       [ 0.38104597,  0.61818308,  0.42679778],\n",
       "       [ 0.24121493,  0.54513943,  0.59411198],\n",
       "       [ 0.37891623,  0.55851114,  0.53711754],\n",
       "       [ 0.4263446 ,  0.53707159,  0.4537847 ],\n",
       "       [ 0.33932132,  0.64984673,  0.35640505],\n",
       "       [ 0.45746928,  0.41720709,  0.41148266],\n",
       "       [ 0.39226913,  0.52258843,  0.45055577],\n",
       "       [ 0.44533378,  0.55167335,  0.44076979],\n",
       "       [ 0.30403751,  0.55210817,  0.39021838],\n",
       "       [ 0.50158572,  0.41984588,  0.44121078],\n",
       "       [ 0.44821462,  0.52030689,  0.48709902],\n",
       "       [ 0.51515913,  0.47667816,  0.3842513 ],\n",
       "       [ 0.52389008,  0.46757397,  0.43600908],\n",
       "       [ 0.4996928 ,  0.53720695,  0.35187495],\n",
       "       [ 0.47812122,  0.27066177,  0.54867774],\n",
       "       [ 0.42794079,  0.37277234,  0.49754757],\n",
       "       [ 0.40147772,  0.57954037,  0.40275052],\n",
       "       [ 0.52276129,  0.51655555,  0.24764664],\n",
       "       [ 0.4745622 ,  0.56113362,  0.26544014],\n",
       "       [ 0.33990055,  0.56503677,  0.52825475],\n",
       "       [ 0.53001684,  0.48628733,  0.19811109],\n",
       "       [ 0.38296628,  0.60333699,  0.34429488],\n",
       "       [ 0.45970109,  0.44223085,  0.46229443],\n",
       "       [ 0.32561859,  0.43844643,  0.50081623],\n",
       "       [ 0.30284989,  0.56403917,  0.51655775],\n",
       "       [ 0.30884132,  0.63635677,  0.42893153],\n",
       "       [ 0.46269447,  0.52713829,  0.22050001],\n",
       "       [ 0.5071224 ,  0.51430553,  0.35370669],\n",
       "       [ 0.20793495,  0.58004624,  0.4441916 ],\n",
       "       [ 0.3983039 ,  0.55694276,  0.41957858],\n",
       "       [ 0.49899185,  0.54715025,  0.31332147],\n",
       "       [ 0.51330388,  0.5002833 ,  0.41497719],\n",
       "       [ 0.34455401,  0.65138727,  0.39640078],\n",
       "       [ 0.45648712,  0.45420021,  0.4764739 ],\n",
       "       [ 0.29386541,  0.6050154 ,  0.42905119]], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_j.predict(xvalid_j_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  64/1176 [>.............................] - ETA: 2s - loss: 0.7982 - acc: 0.5104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py:953: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7868 - acc: 0.5105\n",
      "Epoch 2/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7680 - acc: 0.5162\n",
      "Epoch 3/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7587 - acc: 0.5156\n",
      "Epoch 4/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7346 - acc: 0.5334\n",
      "Epoch 5/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7385 - acc: 0.5357\n",
      "Epoch 6/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7319 - acc: 0.5266\n",
      "Epoch 7/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7068 - acc: 0.5468\n",
      "Epoch 8/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7124 - acc: 0.5454\n",
      "Epoch 9/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7007 - acc: 0.5496\n",
      "Epoch 10/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.6894 - acc: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1388d0588>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_cnn.fit(xtrain_j_padded, ytrain_j_encode, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the third writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/id.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/label.3class.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/label.4class.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/rating.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/subj.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scott = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "# y_s is a column with 3 values: 0,1,2\n",
    "y_s = scott['3class_label']\n",
    "scott['n']=scott.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "scott[\"neg\"]=scott.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "scott[\"pos\"]=scott.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "# y_s_encode are three columns with binary values for each column\n",
    "y_s_encode = scott[['n', 'neg', 'pos']]\n",
    "x_s = scott['subj_extraction']\n",
    "x_s_padded = gd.padded_doc(x_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_s, xvalid_s, ytrain_s, yvalid_s = train_test_split(x_s_padded, y_s,  \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_s, xvalid_s, ytrain_s_encode, yvalid_s_encode = train_test_split(x_s_padded, y_s_encode, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the fourth writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/id.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/label.3class.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/label.4class.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/rating.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/subj.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rhodes = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "# y_s is a column with 3 values: 0,1,2\n",
    "y_r = scott['3class_label']\n",
    "Rhodes['n']=Rhodes.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "Rhodes[\"neg\"]=Rhodes.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "Rhodes[\"pos\"]=Rhodes.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "# y_s_encode are three columns with binary values for each column\n",
    "y_r_encode = Rhodes[['n', 'neg', 'pos']]\n",
    "x_r = Rhodes['subj_extraction']\n",
    "x_r_padded = gd.padded_doc(x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_r_padded, xvalid_r_padded, ytrain_r, yvalid_r = train_test_split(x_r_padded, y_r,  \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_r_padded, xvalid_r_padded, ytrain_r_encode, yvalid_r_encode = train_test_split(x_r_padded, y_r_encode, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparation: total text for embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total text\n",
    "x_d = list(x_d)\n",
    "x_j = list(x_j)\n",
    "x_s = list(x_s)\n",
    "x_r = list(x_r)\n",
    "total_text = x_d+x_j+x_s+x_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding_matrix for total_text\n",
    "vocab_size, embedding_matrix, padded_docs = gd.get_glove_m(total_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparation: get padded text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model from the first writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with glove weights, shape (41441, 100)\n"
     ]
    }
   ],
   "source": [
    "Model_cnn = build_model(embedding_matrix, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 1.0485 - acc: 0.3355\n",
      "Epoch 2/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9433 - acc: 0.3550\n",
      "Epoch 3/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9428 - acc: 0.3983\n",
      "Epoch 4/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9284 - acc: 0.4091\n",
      "Epoch 5/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9241 - acc: 0.4253\n",
      "Epoch 6/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9233 - acc: 0.4405\n",
      "Epoch 7/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9256 - acc: 0.4275\n",
      "Epoch 8/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9182 - acc: 0.4318\n",
      "Epoch 9/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9134 - acc: 0.4318\n",
      "Epoch 10/10\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.9119 - acc: 0.4318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138d5cc50>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_cnn.fit(xtrain_d_padded, ytrain_d_encode, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_cnn_json = model.to_json()\n",
    "with open(\"model_gl_cnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_cnn_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on the second (pretrained on B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0767 - acc: 0.3822\n",
      "Epoch 2/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0709 - acc: 0.3822\n",
      "Epoch 3/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0714 - acc: 0.3798\n",
      "Epoch 4/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0808 - acc: 0.3810\n",
      "Epoch 5/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0612 - acc: 0.3847\n",
      "Epoch 6/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0583 - acc: 0.3859\n",
      "Epoch 7/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0680 - acc: 0.3896\n",
      "Epoch 8/10\n",
      "811/811 [==============================] - 3s 3ms/step - loss: 1.0662 - acc: 0.3933\n",
      "Epoch 9/10\n",
      "811/811 [==============================] - 3s 3ms/step - loss: 1.0477 - acc: 0.3933\n",
      "Epoch 10/10\n",
      "811/811 [==============================] - 2s 3ms/step - loss: 1.0436 - acc: 0.3872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13fb20978>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_cnn.fit(xtrain_j_padded, ytrain_j_encode, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 247us/step\n",
      "acc: 54.21%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.81836802,  0.93762517,  0.77988225],\n",
       "       [ 0.68789679,  0.93742245,  0.75056595],\n",
       "       [ 0.71980613,  0.9147976 ,  0.77256364],\n",
       "       [ 0.68642354,  0.91774011,  0.78740674],\n",
       "       [ 0.69518661,  0.90007198,  0.70963788],\n",
       "       [ 0.71924949,  0.90312862,  0.78281647],\n",
       "       [ 0.64705807,  0.94560784,  0.83421904],\n",
       "       [ 0.59793162,  0.88889885,  0.74650306],\n",
       "       [ 0.57446182,  0.88032877,  0.78512013],\n",
       "       [ 0.68418664,  0.91499037,  0.78228426],\n",
       "       [ 0.75535387,  0.9332456 ,  0.81973702],\n",
       "       [ 0.74912798,  0.93696374,  0.72559249],\n",
       "       [ 0.67369902,  0.93870443,  0.80707961],\n",
       "       [ 0.61071694,  0.93996388,  0.80251342],\n",
       "       [ 0.71017903,  0.91614455,  0.80288166],\n",
       "       [ 0.64273942,  0.93425745,  0.79099518],\n",
       "       [ 0.67749566,  0.90729791,  0.77032697],\n",
       "       [ 0.59798819,  0.91707909,  0.80967766],\n",
       "       [ 0.69291252,  0.9386313 ,  0.78256845],\n",
       "       [ 0.72203147,  0.95351833,  0.78164041],\n",
       "       [ 0.69630164,  0.90479159,  0.81340337],\n",
       "       [ 0.71930724,  0.94637632,  0.77669054],\n",
       "       [ 0.68359697,  0.90746999,  0.74371165],\n",
       "       [ 0.77166748,  0.95046175,  0.76314396],\n",
       "       [ 0.68695283,  0.93163872,  0.84262758],\n",
       "       [ 0.55748582,  0.90813458,  0.66367561],\n",
       "       [ 0.67135632,  0.89292824,  0.76888883],\n",
       "       [ 0.57583117,  0.89917415,  0.88388985],\n",
       "       [ 0.65707684,  0.93754321,  0.71790045],\n",
       "       [ 0.70526969,  0.90567559,  0.84361297],\n",
       "       [ 0.71721911,  0.92472899,  0.68898946],\n",
       "       [ 0.5711211 ,  0.88743943,  0.76770276],\n",
       "       [ 0.64106566,  0.94645184,  0.77550358],\n",
       "       [ 0.65855336,  0.90464282,  0.70336097],\n",
       "       [ 0.74469459,  0.95245445,  0.80104822],\n",
       "       [ 0.67374849,  0.94504631,  0.75951105],\n",
       "       [ 0.65699214,  0.94889438,  0.78233337],\n",
       "       [ 0.68399566,  0.95807832,  0.78548592],\n",
       "       [ 0.57761025,  0.95089531,  0.78510892],\n",
       "       [ 0.51097077,  0.89250159,  0.70786691],\n",
       "       [ 0.72052968,  0.91147459,  0.83017796],\n",
       "       [ 0.53799814,  0.91801858,  0.66788322],\n",
       "       [ 0.64854473,  0.91891062,  0.86072475],\n",
       "       [ 0.70717788,  0.92946464,  0.77885002],\n",
       "       [ 0.67274821,  0.93988013,  0.81314224],\n",
       "       [ 0.61923611,  0.92885053,  0.75066555],\n",
       "       [ 0.67671204,  0.89013761,  0.76878202],\n",
       "       [ 0.58033544,  0.87589139,  0.75265127],\n",
       "       [ 0.5571841 ,  0.92874861,  0.74848604],\n",
       "       [ 0.65744597,  0.91372764,  0.76099157],\n",
       "       [ 0.75714892,  0.93483371,  0.75502014],\n",
       "       [ 0.67416489,  0.89971155,  0.72400171],\n",
       "       [ 0.64748025,  0.94320172,  0.79531938],\n",
       "       [ 0.63086367,  0.92620099,  0.82309443],\n",
       "       [ 0.67937422,  0.91499418,  0.84209335],\n",
       "       [ 0.74183249,  0.93366206,  0.76908177],\n",
       "       [ 0.70314687,  0.94241536,  0.76691061],\n",
       "       [ 0.67504275,  0.92745668,  0.82030678],\n",
       "       [ 0.71066684,  0.94108915,  0.80430669],\n",
       "       [ 0.8055169 ,  0.94549495,  0.83752948],\n",
       "       [ 0.65088499,  0.94999504,  0.64681953],\n",
       "       [ 0.62774378,  0.87380522,  0.75135082],\n",
       "       [ 0.66533977,  0.94645411,  0.82947564],\n",
       "       [ 0.68364388,  0.93861699,  0.74420071],\n",
       "       [ 0.65988922,  0.93605089,  0.67239392],\n",
       "       [ 0.77062857,  0.93614197,  0.74623752],\n",
       "       [ 0.70954025,  0.94147742,  0.74921501],\n",
       "       [ 0.53777921,  0.91922778,  0.75545156],\n",
       "       [ 0.68354845,  0.91748434,  0.75436676],\n",
       "       [ 0.64342445,  0.94205672,  0.72756463],\n",
       "       [ 0.69935244,  0.92071998,  0.73195153],\n",
       "       [ 0.444049  ,  0.87520009,  0.80886066],\n",
       "       [ 0.62177891,  0.9270907 ,  0.7377432 ],\n",
       "       [ 0.57530379,  0.92103195,  0.69161707],\n",
       "       [ 0.73876089,  0.95431185,  0.70120925],\n",
       "       [ 0.59514958,  0.93017876,  0.71636403],\n",
       "       [ 0.54395568,  0.90379542,  0.8239122 ],\n",
       "       [ 0.77272177,  0.94683522,  0.75384068],\n",
       "       [ 0.58232504,  0.89427108,  0.73622692],\n",
       "       [ 0.60067642,  0.89795119,  0.75367451],\n",
       "       [ 0.60777217,  0.8978653 ,  0.79647392],\n",
       "       [ 0.69221532,  0.94014084,  0.84537697],\n",
       "       [ 0.66246283,  0.92342204,  0.83994901],\n",
       "       [ 0.68166959,  0.9437204 ,  0.75947392],\n",
       "       [ 0.70924079,  0.94712591,  0.86296958],\n",
       "       [ 0.62842226,  0.94663769,  0.85797513],\n",
       "       [ 0.58140713,  0.90597939,  0.75898886],\n",
       "       [ 0.66441411,  0.94631773,  0.73606622],\n",
       "       [ 0.47065106,  0.92785901,  0.65290272],\n",
       "       [ 0.71977419,  0.9432714 ,  0.77361006],\n",
       "       [ 0.6647591 ,  0.9295966 ,  0.7408011 ]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_cnn.evaluate(xvalid_j_padded, yvalid_j_encode, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (Model_cnn.metrics_names[1], score[1]*100))\n",
    "Model_cnn.predict(xvalid_j_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "91/91 [==============================] - 1s 8ms/step\n",
      "acc: 54.21%\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_gl_cnn.json', 'r')\n",
    "loaded_model_cnn_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_cnn = model_from_json(loaded_model_cnn_json)\n",
    "# load weights into new model\n",
    "loaded_model_cnn.load_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model_cnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model_cnn.evaluate(xvalid_j_padded, yvalid_j_encode, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model_cnn.metrics_names[1], score[1]*100))\n",
    "# loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
