{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "# ## Plotly\n",
    "# import plotly.offline as py\n",
    "# import plotly.graph_objs as go\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.3class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.4class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/rating.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>3class_label</th>\n",
       "      <th>4class_label</th>\n",
       "      <th>rating</th>\n",
       "      <th>subj_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>in my opinion , a movie reviewer's most import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>you can watch this movie , that is based on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is asking a lot to believe , and though i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>no heroes and no story are the main attributes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is not an art movie , yet i saw it an art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  3class_label  4class_label  rating  \\\n",
       "0  29420             0             0     0.1   \n",
       "1  17219             0             0     0.2   \n",
       "2  18406             0             0     0.2   \n",
       "3  18648             0             0     0.2   \n",
       "4  20021             0             0     0.2   \n",
       "\n",
       "                                     subj_extraction  \n",
       "0  in my opinion , a movie reviewer's most import...  \n",
       "1  you can watch this movie , that is based on a ...  \n",
       "2  this is asking a lot to believe , and though i...  \n",
       "3  no heroes and no story are the main attributes...  \n",
       "4  this is not an art movie , yet i saw it an art...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dennis = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "dennis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dennis[\"strongly neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "dennis[\"strongly pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "dennis['n']=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "y_d_encode = dennis[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_d, xvalid_d, ytrain_d, yvalid_d = train_test_split(list(dennis['subj_extraction']), y_d, \n",
    "                                                  stratify=y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_d, xvalid_d, ytrain_d_encode, yvalid_d_encode = train_test_split(dennis['subj_extraction'], y_d_encode, \n",
    "                                                  stratify=y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924,)\n",
      "(924, 3)\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "# we use x_train as docs, y_d as labels\n",
    "print (ytrain_d.shape)\n",
    "print (ytrain_d_encode.shape)\n",
    "print(len(xtrain_d[1].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(c,f):\n",
    "    return c,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 3, 9, 10, 11, 5, 12, 1, 13, 14, 15], [2, 16, 6, 4, 2, 17, 18, 19, 1, 20, 7, 21, 2, 6, 22, 7, 23, 4, 3, 24, 25], [26, 1, 27, 4, 2, 28], [5, 1, 3, 29, 30, 31, 32]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3,  9, 10, 11,  5, 12,  1, 13, 14, 15],\n",
       "       [21,  2,  6, 22,  7, 23,  4,  3, 24, 25],\n",
       "       [26,  1, 27,  4,  2, 28,  0,  0,  0,  0],\n",
       "       [ 5,  1,  3, 29, 30, 31, 32,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['having a dark humor about it that is funnier than hell', 'the american title to the film , boiling point , is misleading : in japanese the title refers in slang to a baseball score', 'she is going to the library', \n",
    "      'it is a call for artistic freedom']\n",
    "def padded_doc(docs):\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(docs)\n",
    "    # integer encode the documents\n",
    "    encoded_docs = t.texts_to_sequences(docs)\n",
    "    # pad documents to a max length of 4 words\n",
    "    max_length = 10\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    # print(padded_docs)\n",
    "    return padded_docs\n",
    "padded_doc(docs)\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "print (t.texts_to_sequences(docs))\n",
    "padded_doc(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,f = x(7,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glove_dl21 as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, embedding_matrix, padded_docs = gd.get_glove_m(xtrain_d, ytrain_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.27085999,  0.044006  , -0.02026   , ..., -0.4923    ,\n",
       "         0.63687003,  0.23642001],\n",
       "       ..., \n",
       "       [ 0.49579999, -0.41578001,  0.19389001, ..., -0.30579001,\n",
       "         0.45275   ,  0.76160002],\n",
       "       [-0.46489999, -1.06060004, -0.10805   , ...,  0.036301  ,\n",
       "        -0.85459   ,  0.29347   ],\n",
       "       [-0.032544  ,  0.093303  ,  0.0076568 , ...,  0.63237   ,\n",
       "         0.43331   ,  0.84724998]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_padded_docs = gd.padded_doc(xvalid_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17911, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, 400)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (embedding_matrix.shape)\n",
    "vocab_size\n",
    "padded_docs.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with glove weights, shape (17911, 100)\n",
      "Epoch 1/50\n",
      "924/924 [==============================] - 6s 6ms/step - loss: 0.9858 - acc: 0.3972\n",
      "Epoch 2/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.9668 - acc: 0.4145\n",
      "Epoch 3/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.9404 - acc: 0.4297\n",
      "Epoch 4/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.9486 - acc: 0.4275\n",
      "Epoch 5/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.9197 - acc: 0.4286\n",
      "Epoch 6/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.9193 - acc: 0.4297\n",
      "Epoch 7/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.9102 - acc: 0.4253\n",
      "Epoch 8/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.8818 - acc: 0.4307\n",
      "Epoch 9/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.8632 - acc: 0.4275\n",
      "Epoch 10/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.8719 - acc: 0.4286\n",
      "Epoch 11/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.8643 - acc: 0.4307\n",
      "Epoch 12/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.8598 - acc: 0.4361\n",
      "Epoch 13/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.8382 - acc: 0.4437\n",
      "Epoch 14/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.8226 - acc: 0.4340\n",
      "Epoch 15/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.7936 - acc: 0.4654\n",
      "Epoch 16/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.8021 - acc: 0.4848\n",
      "Epoch 17/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.7951 - acc: 0.4903\n",
      "Epoch 18/50\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.7458 - acc: 0.5422\n",
      "Epoch 19/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.7581 - acc: 0.5141\n",
      "Epoch 20/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.7141 - acc: 0.5693\n",
      "Epoch 21/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.7076 - acc: 0.5779\n",
      "Epoch 22/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.6816 - acc: 0.5909\n",
      "Epoch 23/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.6708 - acc: 0.6082\n",
      "Epoch 24/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.6392 - acc: 0.6374\n",
      "Epoch 25/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.6163 - acc: 0.6569\n",
      "Epoch 26/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.6014 - acc: 0.6569\n",
      "Epoch 27/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.5889 - acc: 0.6526\n",
      "Epoch 28/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.5266 - acc: 0.6677\n",
      "Epoch 29/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.5400 - acc: 0.6786\n",
      "Epoch 30/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.5259 - acc: 0.6829\n",
      "Epoch 31/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.5314 - acc: 0.6840\n",
      "Epoch 32/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.4818 - acc: 0.7024\n",
      "Epoch 33/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.4619 - acc: 0.7110\n",
      "Epoch 34/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.4529 - acc: 0.7186\n",
      "Epoch 35/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.4191 - acc: 0.7338\n",
      "Epoch 36/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.4714 - acc: 0.7197\n",
      "Epoch 37/50\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.4035 - acc: 0.7327\n",
      "Epoch 38/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.4213 - acc: 0.7381\n",
      "Epoch 39/50\n",
      "924/924 [==============================] - 6s 6ms/step - loss: 0.3929 - acc: 0.7532\n",
      "Epoch 40/50\n",
      "924/924 [==============================] - 5s 6ms/step - loss: 0.3702 - acc: 0.7457\n",
      "Epoch 41/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.3925 - acc: 0.7392\n",
      "Epoch 42/50\n",
      "924/924 [==============================] - 6s 6ms/step - loss: 0.3583 - acc: 0.7554\n",
      "Epoch 43/50\n",
      "924/924 [==============================] - 6s 6ms/step - loss: 0.3214 - acc: 0.7825\n",
      "Epoch 44/50\n",
      "924/924 [==============================] - 6s 6ms/step - loss: 0.3362 - acc: 0.7738\n",
      "Epoch 45/50\n",
      "924/924 [==============================] - 6s 7ms/step - loss: 0.3582 - acc: 0.7835\n",
      "Epoch 46/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.3340 - acc: 0.7868\n",
      "Epoch 47/50\n",
      "924/924 [==============================] - 5s 6ms/step - loss: 0.3307 - acc: 0.7944\n",
      "Epoch 48/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.3111 - acc: 0.7922\n",
      "Epoch 49/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.2714 - acc: 0.7900\n",
      "Epoch 50/50\n",
      "924/924 [==============================] - 5s 5ms/step - loss: 0.2517 - acc: 0.8128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116ff52e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "# define model\n",
    "embedding_dim = 50\n",
    "filter_sizes = (2, 4)\n",
    "num_filters = 10\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims = 50\n",
    "\n",
    "# Build model\n",
    "sequence_length = 400\n",
    "input_shape = (sequence_length,)\n",
    "\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "# Static model does not have embedding layer\n",
    "\n",
    "z = Embedding(vocab_size, 100, input_length=sequence_length,weights=[embedding_matrix], name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=1)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(3, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "weights = np.array([v for v in embedding_matrix])\n",
    "print(\"Initializing embedding layer with glove weights, shape\", weights.shape)\n",
    "embedding_layer = model.get_layer(\"embedding\")\n",
    "embedding_layer.set_weights([weights])\n",
    "\n",
    "# # Initialize weights with word2vec\n",
    "# if model_type == \"CNN-non-static\":\n",
    "#     weights = np.array([v for v in embedding_weights.values()])\n",
    "#     print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "#     embedding_layer = model.get_layer(\"embedding\")\n",
    "#     embedding_layer.set_weights([weights])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_docs, ytrain_d_encode, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 400, 100)     1791100     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 100)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 399, 10)      2010        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 397, 10)      4010        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 399, 10)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 397, 10)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3990)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3970)         0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7960)         0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7960)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           398050      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            153         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,195,323\n",
      "Trainable params: 2,195,323\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-936885d6e983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre_pro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_padded_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pre_pro = model.predict(x_test_padded_docs)\n",
    "pre = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visuliaze the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 4, 100)            1791100   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 4, 60)             38640     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,832,841\n",
      "Trainable params: 41,741\n",
      "Non-trainable params: 1,791,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "924/924 [==============================] - 3s 3ms/step - loss: 0.5099 - acc: 0.4113\n",
      "Epoch 2/50\n",
      "924/924 [==============================] - 0s 407us/step - loss: 0.3823 - acc: 0.4156\n",
      "Epoch 3/50\n",
      "924/924 [==============================] - 0s 410us/step - loss: 0.3426 - acc: 0.4156\n",
      "Epoch 4/50\n",
      "924/924 [==============================] - 0s 457us/step - loss: 0.3002 - acc: 0.4156\n",
      "Epoch 5/50\n",
      "924/924 [==============================] - 0s 435us/step - loss: 0.2749 - acc: 0.4167\n",
      "Epoch 6/50\n",
      "924/924 [==============================] - 0s 411us/step - loss: 0.2185 - acc: 0.4177\n",
      "Epoch 7/50\n",
      "924/924 [==============================] - 0s 417us/step - loss: 0.1170 - acc: 0.4286\n",
      "Epoch 8/50\n",
      "924/924 [==============================] - 0s 413us/step - loss: -0.0288 - acc: 0.4307\n",
      "Epoch 9/50\n",
      "924/924 [==============================] - 0s 447us/step - loss: -0.2122 - acc: 0.4535\n",
      "Epoch 10/50\n",
      "924/924 [==============================] - 0s 417us/step - loss: -0.4580 - acc: 0.4437\n",
      "Epoch 11/50\n",
      "924/924 [==============================] - 0s 407us/step - loss: -0.5103 - acc: 0.4426\n",
      "Epoch 12/50\n",
      "924/924 [==============================] - 0s 437us/step - loss: -0.6998 - acc: 0.4675\n",
      "Epoch 13/50\n",
      "924/924 [==============================] - 0s 450us/step - loss: -0.8009 - acc: 0.4697\n",
      "Epoch 14/50\n",
      "924/924 [==============================] - 0s 417us/step - loss: -0.9721 - acc: 0.4675\n",
      "Epoch 15/50\n",
      "924/924 [==============================] - 0s 459us/step - loss: -1.0345 - acc: 0.4686\n",
      "Epoch 16/50\n",
      "924/924 [==============================] - 0s 388us/step - loss: -1.1403 - acc: 0.4859\n",
      "Epoch 17/50\n",
      "924/924 [==============================] - 0s 432us/step - loss: -1.2852 - acc: 0.4978\n",
      "Epoch 18/50\n",
      "924/924 [==============================] - 0s 418us/step - loss: -1.3268 - acc: 0.4859\n",
      "Epoch 19/50\n",
      "924/924 [==============================] - 0s 415us/step - loss: -1.3318 - acc: 0.4989\n",
      "Epoch 20/50\n",
      "924/924 [==============================] - 0s 427us/step - loss: -1.4547 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "924/924 [==============================] - 0s 411us/step - loss: -1.6309 - acc: 0.5195\n",
      "Epoch 22/50\n",
      "924/924 [==============================] - 0s 403us/step - loss: -1.7255 - acc: 0.5216\n",
      "Epoch 23/50\n",
      "924/924 [==============================] - 0s 410us/step - loss: -1.7703 - acc: 0.5335\n",
      "Epoch 24/50\n",
      "924/924 [==============================] - 0s 416us/step - loss: -1.7480 - acc: 0.5281\n",
      "Epoch 25/50\n",
      "924/924 [==============================] - 0s 402us/step - loss: -1.9680 - acc: 0.5206\n",
      "Epoch 26/50\n",
      "924/924 [==============================] - 0s 403us/step - loss: -2.0581 - acc: 0.5400\n",
      "Epoch 27/50\n",
      "924/924 [==============================] - 0s 430us/step - loss: -1.9920 - acc: 0.5368\n",
      "Epoch 28/50\n",
      "924/924 [==============================] - 0s 439us/step - loss: -2.0872 - acc: 0.5400\n",
      "Epoch 29/50\n",
      "924/924 [==============================] - 0s 406us/step - loss: -2.2414 - acc: 0.5563\n",
      "Epoch 30/50\n",
      "924/924 [==============================] - 0s 427us/step - loss: -2.3933 - acc: 0.5649\n",
      "Epoch 31/50\n",
      "924/924 [==============================] - 0s 437us/step - loss: -2.3511 - acc: 0.5606\n",
      "Epoch 32/50\n",
      "924/924 [==============================] - 0s 435us/step - loss: -2.4007 - acc: 0.5628\n",
      "Epoch 33/50\n",
      "924/924 [==============================] - 0s 397us/step - loss: -2.5438 - acc: 0.5985\n",
      "Epoch 34/50\n",
      "924/924 [==============================] - 0s 351us/step - loss: -2.5344 - acc: 0.5985\n",
      "Epoch 35/50\n",
      "924/924 [==============================] - 0s 402us/step - loss: -2.6199 - acc: 0.5942\n",
      "Epoch 36/50\n",
      "924/924 [==============================] - 0s 426us/step - loss: -2.6682 - acc: 0.5920\n",
      "Epoch 37/50\n",
      "924/924 [==============================] - 0s 449us/step - loss: -2.6944 - acc: 0.5823\n",
      "Epoch 38/50\n",
      "924/924 [==============================] - 0s 356us/step - loss: -2.7497 - acc: 0.5855\n",
      "Epoch 39/50\n",
      "924/924 [==============================] - 0s 414us/step - loss: -2.8366 - acc: 0.6147\n",
      "Epoch 40/50\n",
      "924/924 [==============================] - 0s 413us/step - loss: -2.8578 - acc: 0.6299\n",
      "Epoch 41/50\n",
      "924/924 [==============================] - 0s 406us/step - loss: -2.7756 - acc: 0.6158\n",
      "Epoch 42/50\n",
      "924/924 [==============================] - 0s 445us/step - loss: -2.9687 - acc: 0.6136\n",
      "Epoch 43/50\n",
      "924/924 [==============================] - 0s 388us/step - loss: -2.9737 - acc: 0.6310\n",
      "Epoch 44/50\n",
      "924/924 [==============================] - 0s 388us/step - loss: -3.0331 - acc: 0.6569\n",
      "Epoch 45/50\n",
      "924/924 [==============================] - 0s 394us/step - loss: -2.9751 - acc: 0.6288\n",
      "Epoch 46/50\n",
      "924/924 [==============================] - 0s 408us/step - loss: -3.0053 - acc: 0.6331\n",
      "Epoch 47/50\n",
      "924/924 [==============================] - 0s 402us/step - loss: -3.0667 - acc: 0.6558\n",
      "Epoch 48/50\n",
      "924/924 [==============================] - 0s 426us/step - loss: -3.0881 - acc: 0.6645\n",
      "Epoch 49/50\n",
      "924/924 [==============================] - 0s 439us/step - loss: -3.1089 - acc: 0.6461\n",
      "Epoch 50/50\n",
      "924/924 [==============================] - 0s 462us/step - loss: -3.1291 - acc: 0.6591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ea94ac8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\n",
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "# model.add(Flatten())\n",
    "model.add(LSTM(60, return_sequences=True,name='lstm_layer',dropout=0.1,recurrent_dropout=0.1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, ytrain_d, epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-18c7c1b025ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.660194\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test_padded_docs, yvalid_d, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d_glv = np.array(xtrain_d_glv)\n",
    "xvalid_d_glv = np.array(xvalid_d_glv)\n",
    "xtrain_d_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 300\n",
    "def model_3_layer():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation = 'relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "#     model.compile(optimizer='rmsprop', \n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "    model.compile(optimizer='rmsprop', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    print ('compile done')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X, y):\n",
    "    model.fit(X,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 286,211\n",
      "Trainable params: 286,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n"
     ]
    }
   ],
   "source": [
    "model = model_3_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 739 samples, validate on 185 samples\n",
      "Epoch 1/10\n",
      "739/739 [==============================] - 1s 1ms/step - loss: 0.6900 - acc: 0.6978 - val_loss: 0.6874 - val_acc: 0.7027\n",
      "Epoch 2/10\n",
      "739/739 [==============================] - 0s 276us/step - loss: 0.6854 - acc: 0.7032 - val_loss: 0.6833 - val_acc: 0.7027\n",
      "Epoch 3/10\n",
      "739/739 [==============================] - 0s 239us/step - loss: 0.6813 - acc: 0.7032 - val_loss: 0.6792 - val_acc: 0.7027\n",
      "Epoch 4/10\n",
      "739/739 [==============================] - 0s 269us/step - loss: 0.6773 - acc: 0.7032 - val_loss: 0.6753 - val_acc: 0.7027\n",
      "Epoch 5/10\n",
      "739/739 [==============================] - ETA: 0s - loss: 0.6735 - acc: 0.700 - 0s 282us/step - loss: 0.6734 - acc: 0.7032 - val_loss: 0.6715 - val_acc: 0.7027\n",
      "Epoch 6/10\n",
      "739/739 [==============================] - 0s 274us/step - loss: 0.6695 - acc: 0.7032 - val_loss: 0.6678 - val_acc: 0.7027\n",
      "Epoch 7/10\n",
      "739/739 [==============================] - 0s 356us/step - loss: 0.6658 - acc: 0.7032 - val_loss: 0.6642 - val_acc: 0.7027\n",
      "Epoch 8/10\n",
      "739/739 [==============================] - 0s 379us/step - loss: 0.6623 - acc: 0.7032 - val_loss: 0.6609 - val_acc: 0.7027\n",
      "Epoch 9/10\n",
      "739/739 [==============================] - 0s 296us/step - loss: 0.6589 - acc: 0.7032 - val_loss: 0.6575 - val_acc: 0.7027\n",
      "Epoch 10/10\n",
      "739/739 [==============================] - 0s 292us/step - loss: 0.6556 - acc: 0.7032 - val_loss: 0.6543 - val_acc: 0.7027\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_gl.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_cnn_json = model.to_json()\n",
    "with open(\"model_gl_cnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove_nn on the other writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/id.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "# label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"3class_label\"])\n",
    "\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.4class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/rating.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "james = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "james[\"strongly neg\"]=james.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "james[\"strongly pos\"]=james.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "james['n']=james.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "y_j_encode = james[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = james.subj_extraction.values\n",
    "y_j = james['3class_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_j, xvalid_j, ytrain_j, yvalid_j = train_test_split(x_j, y_j, \n",
    "                                                  stratify=y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_j, xvalid_j, ytrain_j_encode, yvalid_j_encode = train_test_split(x_j, y_j_encode, \n",
    "                                                  stratify=y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 300)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_j_glv = [g.sentence_vectorize(sent) for sent in xtrain_j]\n",
    "xvalid_j_glv = [g.sentence_vectorize(sent) for sent in xvalid_j]\n",
    "xtrain_j_glv = np.array(xtrain_j_glv)\n",
    "xvalid_j_glv = np.array(xvalid_j_glv)\n",
    "\n",
    "xtrain_j_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the pre_trained model and evaluate on james directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 73.79%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model_gl.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_gl.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(xvalid_j_glv, yvalid_j_encode, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit 3 layer-nn on james"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 286,211\n",
      "Trainable params: 286,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n"
     ]
    }
   ],
   "source": [
    "model = model_3_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 940 samples, validate on 236 samples\n",
      "Epoch 1/10\n",
      "940/940 [==============================] - 0s 295us/step - loss: 0.6486 - acc: 0.7379 - val_loss: 0.6466 - val_acc: 0.7401\n",
      "Epoch 2/10\n",
      "940/940 [==============================] - 0s 283us/step - loss: 0.6430 - acc: 0.7379 - val_loss: 0.6408 - val_acc: 0.7401\n",
      "Epoch 3/10\n",
      "940/940 [==============================] - 0s 266us/step - loss: 0.6378 - acc: 0.7379 - val_loss: 0.6351 - val_acc: 0.7401\n",
      "Epoch 4/10\n",
      "940/940 [==============================] - 0s 290us/step - loss: 0.6328 - acc: 0.7379 - val_loss: 0.6298 - val_acc: 0.7401\n",
      "Epoch 5/10\n",
      "940/940 [==============================] - 0s 275us/step - loss: 0.6280 - acc: 0.7379 - val_loss: 0.6245 - val_acc: 0.7401\n",
      "Epoch 6/10\n",
      "940/940 [==============================] - 0s 284us/step - loss: 0.6232 - acc: 0.7379 - val_loss: 0.6192 - val_acc: 0.7401\n",
      "Epoch 7/10\n",
      "940/940 [==============================] - 0s 293us/step - loss: 0.6185 - acc: 0.7379 - val_loss: 0.6143 - val_acc: 0.7401\n",
      "Epoch 8/10\n",
      "940/940 [==============================] - 0s 292us/step - loss: 0.6140 - acc: 0.7379 - val_loss: 0.6094 - val_acc: 0.7401\n",
      "Epoch 9/10\n",
      "940/940 [==============================] - 0s 327us/step - loss: 0.6097 - acc: 0.7379 - val_loss: 0.6047 - val_acc: 0.7401\n",
      "Epoch 10/10\n",
      "940/940 [==============================] - 0s 261us/step - loss: 0.6055 - acc: 0.7379 - val_loss: 0.6001 - val_acc: 0.7401\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, xtrain_j_glv, ytrain_j_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x12ca334e0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 940 samples, validate on 236 samples\n",
      "Epoch 1/10\n",
      "940/940 [==============================] - 1s 1ms/step - loss: 0.6473 - acc: 0.7379 - val_loss: 0.6486 - val_acc: 0.7401\n",
      "Epoch 2/10\n",
      "940/940 [==============================] - 0s 244us/step - loss: 0.6468 - acc: 0.7379 - val_loss: 0.6480 - val_acc: 0.7401\n",
      "Epoch 3/10\n",
      "940/940 [==============================] - 0s 274us/step - loss: 0.6463 - acc: 0.7379 - val_loss: 0.6474 - val_acc: 0.7401\n",
      "Epoch 4/10\n",
      "940/940 [==============================] - 0s 268us/step - loss: 0.6457 - acc: 0.7379 - val_loss: 0.6469 - val_acc: 0.7401\n",
      "Epoch 5/10\n",
      "940/940 [==============================] - 0s 294us/step - loss: 0.6452 - acc: 0.7379 - val_loss: 0.6463 - val_acc: 0.7401\n",
      "Epoch 6/10\n",
      "940/940 [==============================] - 0s 281us/step - loss: 0.6446 - acc: 0.7379 - val_loss: 0.6457 - val_acc: 0.7401\n",
      "Epoch 7/10\n",
      "940/940 [==============================] - 0s 261us/step - loss: 0.6441 - acc: 0.7379 - val_loss: 0.6452 - val_acc: 0.7401\n",
      "Epoch 8/10\n",
      "940/940 [==============================] - 0s 284us/step - loss: 0.6436 - acc: 0.7379 - val_loss: 0.6446 - val_acc: 0.7401\n",
      "Epoch 9/10\n",
      "940/940 [==============================] - 0s 277us/step - loss: 0.6431 - acc: 0.7379 - val_loss: 0.6440 - val_acc: 0.7401\n",
      "Epoch 10/10\n",
      "940/940 [==============================] - 0s 290us/step - loss: 0.6426 - acc: 0.7379 - val_loss: 0.6435 - val_acc: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1292176a0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.fit(xtrain_j_glv, ytrain_j_encode, batch_size=32,epochs=10,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn on glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128,5,\n",
    "                 activation='relu'))\n",
    "    model.add(MaxPooling1D(5))\n",
    "    model.add(Conv2D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 300\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 100\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000,\n",
    "                    400,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(xtrain_j_glv, ytrain_j_encode,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(xvalid_j_glv, yvalid_j_encode))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
