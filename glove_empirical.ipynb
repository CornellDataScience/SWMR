{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "# ## Plotly\n",
    "# import plotly.offline as py\n",
    "# import plotly.graph_objs as go\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.3class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.4class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/rating.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dennis = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "dennis = dennis.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1027, 8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dennis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']\n",
    "dennis['n']=dennis.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "y_d_encode = dennis[['n', 'neg', 'pos']]\n",
    "x_d = list(dennis['subj_extraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_d, xvalid_d, ytrain_d, yvalid_d = train_test_split(list(dennis['subj_extraction']), y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_d, xvalid_d, ytrain_d_encode, yvalid_d_encode = train_test_split(dennis['subj_extraction'], y_d_encode,  \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/id.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "# label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"3class_label\"])\n",
    "\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.4class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/rating.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "james = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "james = james.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "james['n']=james.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "james[\"neg\"]=james.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "james[\"pos\"]=james.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "y_j_encode = james[['n', 'neg', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_j = james.subj_extraction.values\n",
    "y_j = james['3class_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove_nn on the other writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_j, xvalid_j, ytrain_j, yvalid_j = train_test_split(x_j, y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_j, xvalid_j, ytrain_j_encode, yvalid_j_encode = train_test_split(x_j, y_j_encode, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the third writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/id.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/label.3class.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/label.4class.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/rating.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/subj.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scott = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "scott = scott.sample(frac=1)\n",
    "# y_s is a column with 3 values: 0,1,2\n",
    "y_s = scott['3class_label']\n",
    "scott['n']=scott.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "scott[\"neg\"]=scott.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "scott[\"pos\"]=scott.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "# y_s_encode are three columns with binary values for each column\n",
    "y_s_encode = scott[['n', 'neg', 'pos']]\n",
    "x_s = scott['subj_extraction']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the fourth writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/id.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/label.3class.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/label.4class.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/rating.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Steve+Rhodes/subj.Steve+Rhodes.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rhodes = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "Rhodes = Rhodes.sample(frac=1)\n",
    "# y_s is a column with 3 values: 0,1,2\n",
    "y_r = Rhodes['3class_label']\n",
    "Rhodes['n']=Rhodes.apply(lambda x:x[\"3class_label\"]==0, axis=1)\n",
    "Rhodes[\"neg\"]=Rhodes.apply(lambda x:x[\"3class_label\"]==1, axis=1)\n",
    "Rhodes[\"pos\"]=Rhodes.apply(lambda x:x[\"3class_label\"]==2, axis=1)\n",
    "# y_s_encode are three columns with binary values for each column\n",
    "y_r_encode = Rhodes[['n', 'neg', 'pos']]\n",
    "x_r = Rhodes['subj_extraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total text\n",
    "x_d = list(x_d)\n",
    "x_j = list(x_j)\n",
    "x_s = list(x_s)\n",
    "x_r = list(x_r)\n",
    "total_text = x_d+x_j+x_s+x_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glove_dl22 as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, embedding_matrix, padded_docs = gd.get_glove_m(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46260, 100)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Covert xtest and xtrain to padded doc\n",
    "xvalid_d_padded_docs = gd.padded_doc(xvalid_d)\n",
    "xtrain_d_padded_docs = gd.padded_doc(xtrain_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with glove weights, shape (46260, 100)\n",
      "Epoch 1/50\n",
      "821/821 [==============================] - 2s 3ms/step - loss: 1.1393 - acc: 0.3873\n",
      "Epoch 2/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0881 - acc: 0.4117\n",
      "Epoch 3/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0928 - acc: 0.4068\n",
      "Epoch 4/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0785 - acc: 0.4117\n",
      "Epoch 5/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0846 - acc: 0.4056\n",
      "Epoch 6/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0812 - acc: 0.4275\n",
      "Epoch 7/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0809 - acc: 0.4141\n",
      "Epoch 8/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0773 - acc: 0.4166A: 0s - loss: 1.0775 - acc: 0\n",
      "Epoch 9/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0692 - acc: 0.4300\n",
      "Epoch 10/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0587 - acc: 0.4129\n",
      "Epoch 11/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0489 - acc: 0.4214\n",
      "Epoch 12/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0580 - acc: 0.4178\n",
      "Epoch 13/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0568 - acc: 0.4178\n",
      "Epoch 14/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0561 - acc: 0.4153\n",
      "Epoch 15/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0487 - acc: 0.4263\n",
      "Epoch 16/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0494 - acc: 0.4153\n",
      "Epoch 17/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0443 - acc: 0.4385\n",
      "Epoch 18/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0214 - acc: 0.4275A: 0s - loss: 1.0148 - acc: \n",
      "Epoch 19/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0179 - acc: 0.4300\n",
      "Epoch 20/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0429 - acc: 0.4287\n",
      "Epoch 21/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0275 - acc: 0.4385\n",
      "Epoch 22/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0122 - acc: 0.4507A: 0s - loss: 1.0182 - \n",
      "Epoch 23/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0186 - acc: 0.4190\n",
      "Epoch 24/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 1.0112 - acc: 0.4677\n",
      "Epoch 25/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9940 - acc: 0.4750\n",
      "Epoch 26/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9928 - acc: 0.4994\n",
      "Epoch 27/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9677 - acc: 0.4848\n",
      "Epoch 28/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9584 - acc: 0.4994\n",
      "Epoch 29/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9565 - acc: 0.5128\n",
      "Epoch 30/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9820 - acc: 0.4982\n",
      "Epoch 31/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9293 - acc: 0.5639\n",
      "Epoch 32/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9213 - acc: 0.5469\n",
      "Epoch 33/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9268 - acc: 0.5664\n",
      "Epoch 34/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9021 - acc: 0.5591A: 1s - loss: 0.8\n",
      "Epoch 35/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8839 - acc: 0.5932\n",
      "Epoch 36/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.9345 - acc: 0.5579\n",
      "Epoch 37/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8608 - acc: 0.5932\n",
      "Epoch 38/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8829 - acc: 0.6102\n",
      "Epoch 39/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8308 - acc: 0.6163\n",
      "Epoch 40/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8342 - acc: 0.6175\n",
      "Epoch 41/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8355 - acc: 0.6175\n",
      "Epoch 42/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8273 - acc: 0.6492\n",
      "Epoch 43/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.8004 - acc: 0.6395\n",
      "Epoch 44/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.7729 - acc: 0.6468\n",
      "Epoch 45/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.7978 - acc: 0.6346\n",
      "Epoch 46/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.7510 - acc: 0.6772\n",
      "Epoch 47/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.7215 - acc: 0.6833\n",
      "Epoch 48/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.7268 - acc: 0.6870\n",
      "Epoch 49/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.7019 - acc: 0.6894\n",
      "Epoch 50/50\n",
      "821/821 [==============================] - 2s 2ms/step - loss: 0.7242 - acc: 0.6931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fa2d0b8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "def build_model(embedding_matrix, vocab_size):\n",
    "    # define model\n",
    "    embedding_dim = 50\n",
    "    filter_sizes = (2, 4)\n",
    "    num_filters = 10\n",
    "    dropout_prob = (0.5, 0.8)\n",
    "    hidden_dims = 50\n",
    "\n",
    "    # Build model\n",
    "    sequence_length = 100\n",
    "    input_shape = (sequence_length,)\n",
    "\n",
    "    model_input = Input(shape=input_shape)\n",
    "\n",
    "    # Static model does not have embedding layer\n",
    "\n",
    "    z = Embedding(vocab_size, 100, input_length=sequence_length,weights=[embedding_matrix], name=\"embedding\")(model_input)\n",
    "    z.trainable = False\n",
    "    \n",
    "    z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "    # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = Convolution1D(filters=num_filters,\n",
    "                             kernel_size=sz,\n",
    "                             padding=\"valid\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1)(z)\n",
    "        conv = MaxPooling1D(pool_size=1)(conv)\n",
    "        conv = Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "    z = Dropout(dropout_prob[1])(z)\n",
    "    z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "    model_output = Dense(3, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    weights = np.array([v for v in embedding_matrix])\n",
    "    print(\"Initializing embedding layer with glove weights, shape\", weights.shape)\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights([weights])\n",
    "    return model\n",
    "\n",
    "# # Initialize weights with word2vec\n",
    "# if model_type == \"CNN-non-static\":\n",
    "#     weights = np.array([v for v in embedding_weights.values()])\n",
    "#     print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "#     embedding_layer = model.get_layer(\"embedding\")\n",
    "#     embedding_layer.set_weights([weights])\n",
    "\n",
    "# Train the model\n",
    "model = build_model(embedding_matrix, vocab_size)\n",
    "model.fit(xtrain_d_padded_docs, ytrain_d_encode, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 100)     4626000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100, 100)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 99, 10)       2010        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 97, 10)       4010        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 99, 10)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 97, 10)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 990)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 970)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1960)         0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1960)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           98050       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            153         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,730,223\n",
      "Trainable params: 4,730,223\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visuliaze the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 574us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.113010972448923, 0.40291262193790917]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xvalid_d_padded_docs, yvalid_d_encode, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          n    neg   pos\n",
       "821   False  False  True\n",
       "822   False  False  True\n",
       "823   False  False  True\n",
       "824   False  False  True\n",
       "825   False  False  True\n",
       "826   False  False  True\n",
       "827   False  False  True\n",
       "828   False  False  True\n",
       "829   False  False  True\n",
       "830   False  False  True\n",
       "831   False  False  True\n",
       "832   False  False  True\n",
       "833   False  False  True\n",
       "834   False  False  True\n",
       "835   False  False  True\n",
       "836   False  False  True\n",
       "837   False  False  True\n",
       "838   False  False  True\n",
       "839   False  False  True\n",
       "840   False  False  True\n",
       "841   False  False  True\n",
       "842   False  False  True\n",
       "843   False  False  True\n",
       "844   False  False  True\n",
       "845   False  False  True\n",
       "846   False  False  True\n",
       "847   False  False  True\n",
       "848   False  False  True\n",
       "849   False  False  True\n",
       "850   False  False  True\n",
       "...     ...    ...   ...\n",
       "997   False  False  True\n",
       "998   False  False  True\n",
       "999   False  False  True\n",
       "1000  False  False  True\n",
       "1001  False  False  True\n",
       "1002  False  False  True\n",
       "1003  False  False  True\n",
       "1004  False  False  True\n",
       "1005  False  False  True\n",
       "1006  False  False  True\n",
       "1007  False  False  True\n",
       "1008  False  False  True\n",
       "1009  False  False  True\n",
       "1010  False  False  True\n",
       "1011  False  False  True\n",
       "1012  False  False  True\n",
       "1013  False  False  True\n",
       "1014  False  False  True\n",
       "1015  False  False  True\n",
       "1016  False  False  True\n",
       "1017  False  False  True\n",
       "1018  False  False  True\n",
       "1019  False  False  True\n",
       "1020  False  False  True\n",
       "1021  False  False  True\n",
       "1022  False  False  True\n",
       "1023  False  False  True\n",
       "1024  False  False  True\n",
       "1025  False  False  True\n",
       "1026  False  False  True\n",
       "\n",
       "[206 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yvalid_d_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d_glv = np.array(xtrain_d_glv)\n",
    "xvalid_d_glv = np.array(xvalid_d_glv)\n",
    "xtrain_d_glv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_gl.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_cnn_json = model.to_json()\n",
    "with open(\"model_gl_cnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_cnn_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvalid_j_padded = gd.padded_doc(xvalid_j)\n",
    "xvalid_j_padded.shape\n",
    "xtrain_j_padded = gd.padded_doc(xtrain_j)\n",
    "xtrain_j_padded.shape\n",
    "# xtrain_j_padded = xtrain_j_padded[:924,:]\n",
    "# yvalid_j_encode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the pre_trained model and evaluate on james directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "acc: 39.44%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model_gl_cnn.json', 'r')\n",
    "loaded_model_cnn_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_cnn = model_from_json(loaded_model_cnn_json)\n",
    "# load weights into new model\n",
    "loaded_model_cnn.load_weights(\"model_gl_cnn.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model_cnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model_cnn.evaluate(xvalid_j_padded, yvalid_j_encode, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model_cnn.metrics_names[1], score[1]*100))\n",
    "# loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_text = x_d+x_j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size, embedding_matrix, padded_docs = gd.get_glove_m(total_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33501, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuning freeze the E layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in loaded_model_cnn.layers[:2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x12ac2e208>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "loaded_model_cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1176/1176 [==============================] - 4s 4ms/step - loss: 0.8200 - acc: 0.3104\n",
      "Epoch 2/10\n",
      "1176/1176 [==============================] - 3s 3ms/step - loss: 0.7752 - acc: 0.4337\n",
      "Epoch 3/10\n",
      "1176/1176 [==============================] - 3s 3ms/step - loss: 0.7654 - acc: 0.4515\n",
      "Epoch 4/10\n",
      "1176/1176 [==============================] - 3s 3ms/step - loss: 0.7507 - acc: 0.4541\n",
      "Epoch 5/10\n",
      "1176/1176 [==============================] - 4s 3ms/step - loss: 0.7538 - acc: 0.4549\n",
      "Epoch 6/10\n",
      "1176/1176 [==============================] - 3s 3ms/step - loss: 0.7358 - acc: 0.4575\n",
      "Epoch 7/10\n",
      "1176/1176 [==============================] - 3s 3ms/step - loss: 0.7264 - acc: 0.4549\n",
      "Epoch 8/10\n",
      "1176/1176 [==============================] - 4s 3ms/step - loss: 0.7252 - acc: 0.4541A: 0s - loss: 0.7286 - acc:\n",
      "Epoch 9/10\n",
      "1176/1176 [==============================] - 3s 3ms/step - loss: 0.7224 - acc: 0.4558\n",
      "Epoch 10/10\n",
      "1176/1176 [==============================] - 4s 3ms/step - loss: 0.7030 - acc: 0.4566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ae8ea90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_j_padded, ytrain_j_encode, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  64/1176 [>.............................] - ETA: 2s - loss: 0.7982 - acc: 0.5104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py:953: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7868 - acc: 0.5105\n",
      "Epoch 2/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7680 - acc: 0.5162\n",
      "Epoch 3/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7587 - acc: 0.5156\n",
      "Epoch 4/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7346 - acc: 0.5334\n",
      "Epoch 5/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7385 - acc: 0.5357\n",
      "Epoch 6/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7319 - acc: 0.5266\n",
      "Epoch 7/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7068 - acc: 0.5468\n",
      "Epoch 8/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7124 - acc: 0.5454\n",
      "Epoch 9/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.7007 - acc: 0.5496\n",
      "Epoch 10/10\n",
      "1176/1176 [==============================] - 2s 2ms/step - loss: 0.6894 - acc: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1388d0588>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_cnn.fit(xtrain_j_padded, ytrain_j_encode, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model from the first writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with glove weights, shape (41441, 100)\n"
     ]
    }
   ],
   "source": [
    "pretrainModel_cnn = build_model(embedding_matrix, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
