{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
=======
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 2931d3b0931b4e9cc73ebe8b833be2da557492cb
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.3class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/label.4class.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/rating.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dennis = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>3class_label</th>\n",
       "      <th>4class_label</th>\n",
       "      <th>rating</th>\n",
       "      <th>subj_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>in my opinion , a movie reviewer's most import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>you can watch this movie , that is based on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is asking a lot to believe , and though i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>no heroes and no story are the main attributes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>this is not an art movie , yet i saw it an art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  3class_label  4class_label  rating  \\\n",
       "0  29420             0             0     0.1   \n",
       "1  17219             0             0     0.2   \n",
       "2  18406             0             0     0.2   \n",
       "3  18648             0             0     0.2   \n",
       "4  20021             0             0     0.2   \n",
       "\n",
       "                                     subj_extraction  \n",
       "0  in my opinion , a movie reviewer's most import...  \n",
       "1  you can watch this movie , that is based on a ...  \n",
       "2  this is asking a lot to believe , and though i...  \n",
       "3  no heroes and no story are the main attributes...  \n",
       "4  this is not an art movie , yet i saw it an art...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dennis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dennis[\"strongly neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==0, axis=1)\n",
    "dennis[\"neg\"]=dennis.apply(lambda x:x[\"4class_label\"]==1, axis=1)\n",
    "dennis[\"pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==2, axis=1)\n",
    "dennis[\"strongly pos\"]=dennis.apply(lambda x:x[\"4class_label\"]==3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
=======
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 2931d3b0931b4e9cc73ebe8b833be2da557492cb
   "outputs": [],
   "source": [
    "y_d = dennis['3class_label']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
=======
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 2931d3b0931b4e9cc73ebe8b833be2da557492cb
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_d, xvalid_d, ytrain_d, yvalid_d = train_test_split(dennis['subj_extraction'], y_d, \n",
    "                                                  stratify=y_d, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86     it is a call for artistic freedom , but intere...\n",
       "124    steal this movie ! it meant well , showing the...\n",
       "347    a rather flat film noir that never gets that i...\n",
       "413    takeshi \" beat \" kitano is certainly a unique ...\n",
       "630    as the one giving the orders , the big boss , ...\n",
       "Name: subj_extraction, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
=======
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 2931d3b0931b4e9cc73ebe8b833be2da557492cb
   "outputs": [],
   "source": [
    "loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
=======
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 2931d3b0931b4e9cc73ebe8b833be2da557492cb
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain_d) + list(xvalid_d))\n",
    "xtrain_d_tfv =  tfv.transform(xtrain_d) \n",
    "xvalid_d_tfv = tfv.transform(xvalid_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, 10512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (xtrain_d.shape)\n",
    "xtrain_d_tfv.shape\n",
    "# for t in xtrain_d_tfv:\n",
    "#     print (t)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.935 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "clf_l_t = LogisticRegression(C=1.0)\n",
    "clf_l_t.fit(xtrain_d_tfv, ytrain_d)\n",
    "predictions = clf_l_t.predict_proba(xvalid_d_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_d, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_d_t_l = 0.935"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple Naive Bayes on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.938 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on TFIDF\n",
    "clf_n_t = MultinomialNB()\n",
    "clf_n_t.fit(xtrain_d_tfv, ytrain_d)\n",
    "predictions = clf_n_t.predict_proba(xvalid_d_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_d, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_d_t_n = 0.938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word count model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain_d) + list(xvalid_d))\n",
    "xtrain_d_ctv =  ctv.transform(xtrain_d) \n",
    "xvalid_d_ctv = ctv.transform(xvalid_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple logistic regression on word acount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.735 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on word Counts\n",
    "clf_l_w = LogisticRegression(C=1.0)\n",
    "clf_l_w.fit(xtrain_d_ctv, ytrain_d)\n",
    "predictions = clf_l_w.predict_proba(xvalid_d_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_d, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting word count on a simple naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 2.655 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on word count\n",
    "clf_n_w = MultinomialNB()\n",
    "clf_n_w.fit(xtrain_d_ctv, ytrain_d)\n",
    "predictions = clf_n_w.predict_proba(xvalid_d_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_d, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_d_w_n = 2.655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_trained=True\n",
    "GLOVE_PATH = os.path.dirname(os.getcwd()) + '/models/glove.840B.300d.zip'\n",
    "GLOVE_FILE = 'glove.840B.300d.txt'  # can change it to glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt\n",
    "# load the file\n",
    "if pre_trained:\n",
    "    glove = zipfile.ZipFile(GLOVE_PATH, 'r')\n",
    "    words = pd.read_table(glove.open(GLOVE_FILE), sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "    model = words.as_matrix()\n",
    "else:\n",
    "    model = None\n",
    "# build dictionary\n",
    "if model is not None:\n",
    "    dict1 = {word: i for i, word in enumerate(words.index)}\n",
    "else:\n",
    "    dict1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_vectorize(s):\n",
    "    words = str(s).lower()\n",
    "#     words = word_tokenize(words)\n",
    "#     words = [w for w in words if not w in stop_words]\n",
    "#     words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_d_glv = [sentence_vectorize(sent) for sent in xtrain_d]\n",
    "xvalid_d_glv = [sentence_vectorize(sent) for sent in xvalid_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_d_glv = np.array(xtrain_d_glv)\n",
    "xvalid_d_glv = np.array(xvalid_d_glv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_d_glv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove on Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.072 \n"
     ]
    }
   ],
   "source": [
    "clf_l_g = LogisticRegression(C=1.0)\n",
    "clf_l_g.fit(xtrain_d_glv, ytrain_d)\n",
    "predictions = clf_l_g.predict_proba(xvalid_d_glv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_d, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_g_d = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove on Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.072 \n"
     ]
    }
   ],
   "source": [
    "clf_n_g = MultinomialNB()\n",
    "clf_n_g.fit(xtrain_d_glv, ytrain_d)\n",
    "predictions = clf_n_g.predict_proba(xvalid_d_glv)\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_d, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models above on other writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/id.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "# label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.3class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"3class_label\"])\n",
    "\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/label.4class.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/rating.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>3class_label</th>\n",
       "      <th>4class_label</th>\n",
       "      <th>rating</th>\n",
       "      <th>subj_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>i didn't expect ghost in the machine to be thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>admittedly , with a title like the mangler , y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>cast : christopher lambert , natasha henstridg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>inevitably , someone is going to ask me why i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>ernest : the one-joke concept that refuses to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  3class_label  4class_label  rating  \\\n",
       "0  2321             0             0    0.05   \n",
       "1  3337             0             0    0.05   \n",
       "2  6511             0             0    0.05   \n",
       "3  6912             0             0    0.05   \n",
       "4  2240             0             0    0.09   \n",
       "\n",
       "                                     subj_extraction  \n",
       "0  i didn't expect ghost in the machine to be thi...  \n",
       "1  admittedly , with a title like the mangler , y...  \n",
       "2  cast : christopher lambert , natasha henstridg...  \n",
       "3  inevitably , someone is going to ask me why i ...  \n",
       "4  ernest : the one-joke concept that refuses to ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "james = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "james.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_j = james['3class_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_j, xvalid_j, ytrain_j, yvalid_j = train_test_split(james.subj_extraction.values, y_j, \n",
    "                                                  stratify=y_j, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=10512, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain_j) + list(xvalid_j))\n",
    "xtrain_j_tfv =  tfv.transform(xtrain_j) \n",
    "xvalid_j_tfv = tfv.transform(xvalid_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 10512)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_j_tfv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple Logistic Regression on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.183 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "\n",
    "predictions = clf_l_t.predict_proba(xvalid_j_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_j, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple Naive Bayes on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.816 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on TFIDF\n",
    "# clf_n_t = MultinomialNB()\n",
    "clf_n_t.fit(xtrain_j_tfv, ytrain_j)\n",
    "predictions = clf_n_t.predict_proba(xvalid_j_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_j, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word count model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english', max_features = 255418)\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain_j) + list(xvalid_j))\n",
    "xtrain_j_ctv =  ctv.transform(xtrain_j) \n",
    "xvalid_j_ctv = ctv.transform(xvalid_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple Logistic Regression on word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.278 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on word Counts\n",
    "# clf = LogisticRegression(C=1.0)\n",
    "# clf.fit(xtrain_j_ctv, ytrain_j)\n",
    "predictions = clf_l_w.predict_proba(xvalid_j_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_j, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple Naive Bayes on wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 10.194 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on wordcount\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(xtrain_j_ctv, ytrain_j)\n",
    "predictions = clf_n_w.predict_proba(xvalid_j_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_j, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_j_glv = [sentence_vectorize(sent) for sent in xtrain_j]\n",
    "xvalid_j_glv = [sentence_vectorize(sent) for sent in xvalid_j]\n",
    "xtrain_d_glv = np.array(xtrain_d_glv)\n",
    "xvalid_d_glv = np.array(xvalid_d_glv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Logistic regression on glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.177 \n"
     ]
    }
   ],
   "source": [
    "predictions = clf_l_g.predict_proba(xvalid_j_glv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_j, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting NB on glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data for scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/id.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\", header=None, names=[\"id\"])\n",
    "label_3class = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/label.3class.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\", names=[\"3class_label\"])\n",
    "label_4class = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/label.4class.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"4class_label\"])\n",
    "rating = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/rating.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"rating\"])\n",
    "subj = pd.read_csv(\"scale_data/scaledata/Scott+Renshaw/subj.Scott+Renshaw.txt\", sep=\"[\\r\\n]+\",names=[\"subj_extraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>3class_label</th>\n",
       "      <th>4class_label</th>\n",
       "      <th>rating</th>\n",
       "      <th>subj_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i'm guessing -- and from the available evidenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>there's bad buzz , and then there's the the ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>director : richard rush . director richard rus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>screenplay : johnny brennan &amp; kamal ahmed and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>screenplay : tim burns &amp; tom stern and anthony...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  3class_label  4class_label  rating  \\\n",
       "0  11961             0             0     0.0   \n",
       "1  13915             0             0     0.0   \n",
       "2   2790             0             0     0.0   \n",
       "3   3285             0             0     0.0   \n",
       "4  10264             0             0     0.1   \n",
       "\n",
       "                                     subj_extraction  \n",
       "0  i'm guessing -- and from the available evidenc...  \n",
       "1  there's bad buzz , and then there's the the ba...  \n",
       "2  director : richard rush . director richard rus...  \n",
       "3  screenplay : johnny brennan & kamal ahmed and ...  \n",
       "4  screenplay : tim burns & tom stern and anthony...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scott = pd.concat([ids,label_3class, label_4class, rating, subj], axis = 1)\n",
    "scott.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = james['3class_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_s, xvalid_s, ytrain_s, yvalid_s = train_test_split(james.subj_extraction.values, y_s, \n",
    "                                                  stratify=y_s, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "# tfv = TfidfVectorizer(min_df=3,  max_features=10512, \n",
    "#             strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "#             ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "#             stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain_s) + list(xvalid_s))\n",
    "xtrain_s_tfv =  tfv.transform(xtrain_s) \n",
    "xvalid_s_tfv = tfv.transform(xvalid_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 10512)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_s_tfv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.183 \n"
     ]
    }
   ],
   "source": [
    "predictions = clf_l_t.predict_proba(xvalid_s_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_s, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.816 \n"
     ]
    }
   ],
   "source": [
    "predictions = clf_n_t.predict_proba(xvalid_s_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_s, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english', max_features = 10512)\n",
    "\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain_s) + list(xvalid_s))\n",
    "xtrain_s_ctv =  ctv.transform(xtrain_s) \n",
    "xvalid_s_ctv = ctv.transform(xvalid_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 10512 features per sample; expecting 255418",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-d58aedca3da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_l_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid_s_tfv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"logloss: %0.3f \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmulticlass_logloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myvalid_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mcalculate_ovr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ovr\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcalculate_ovr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 305\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 10512 features per sample; expecting 255418"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = clf_l_w.predict_proba(xvalid_s_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_s, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.178 \n"
     ]
    }
   ],
   "source": [
    "predictions = clf_n_g.predict_proba(xvalid_j_glv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid_j, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>log-loss</th>\n",
       "      <th>writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l_tf</td>\n",
       "      <td>0.935</td>\n",
       "      <td>dennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_tf</td>\n",
       "      <td>0.938</td>\n",
       "      <td>dennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l_w</td>\n",
       "      <td>0.735</td>\n",
       "      <td>dennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_w</td>\n",
       "      <td>2.655</td>\n",
       "      <td>dennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l_g</td>\n",
       "      <td>1.072</td>\n",
       "      <td>dennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_g</td>\n",
       "      <td>1.072</td>\n",
       "      <td>dennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l_tf</td>\n",
       "      <td>1.183</td>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n_tf</td>\n",
       "      <td>0.919</td>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l_w</td>\n",
       "      <td>1.278</td>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n_w</td>\n",
       "      <td>10.194</td>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l_g</td>\n",
       "      <td>1.177</td>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n_g</td>\n",
       "      <td>1.178</td>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classifier  log-loss  writer\n",
       "0        l_tf     0.935  dennis\n",
       "1        n_tf     0.938  dennis\n",
       "2         l_w     0.735  dennis\n",
       "3         n_w     2.655  dennis\n",
       "4         l_g     1.072  dennis\n",
       "5         n_g     1.072  dennis\n",
       "6        l_tf     1.183   James\n",
       "7        n_tf     0.919   James\n",
       "8         l_w     1.278   James\n",
       "9         n_w    10.194   James\n",
       "10        l_g     1.177   James\n",
       "11        n_g     1.178   James"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('comparison_res.csv', delimiter = '\\t')\n",
    "df = df[['classifier', 'log-loss', 'writer']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAELCAYAAADURYGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZ37hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dc63780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"classifier\")\n",
    "plt.ylabel('Log loss')\n",
    "x = [0,1,2,3,4,5]\n",
    "y_dennis = df[:6][\"log-loss\"]\n",
    "y_james = df[6:][\"log-loss\"]\n",
    "my_xticks = df[:6][\"classifier\"]\n",
    "plt.xticks(x, my_xticks)\n",
    "plt.plot(x, y_dennis)\n",
    "plt.plot(x, y_james)\n",
    "plt.legend(['Dennis', 'James'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
